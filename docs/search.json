[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Value of Time Estimation",
    "section": "",
    "text": "This analysis estimates the Value of Time (VOT) parameters for Utah’s travel demand model using income data from the American Community Survey (ACS) 2019-2023 5-Year Estimates. The VOT represents how much travelers value their time, expressed in cents per minute, and is a critical parameter for evaluating transportation projects and predicting mode choice behavior.\nThe methodology segments travelers by income level (low, average, and high) and trip purpose (work vs. personal trips), recognizing that different travelers value their time differently. Work trips typically have higher VOT since travel time directly impacts productivity, while personal trips reflect individuals’ willingness to trade time for money in their leisure activities.\nThis notebook replicates and updates the methodology from the archived Excel workbook, providing a transparent, reproducible workflow using open source data science tools."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Value of Time Estimation",
    "section": "",
    "text": "This analysis estimates the Value of Time (VOT) parameters for Utah’s travel demand model using income data from the American Community Survey (ACS) 2019-2023 5-Year Estimates. The VOT represents how much travelers value their time, expressed in cents per minute, and is a critical parameter for evaluating transportation projects and predicting mode choice behavior.\nThe methodology segments travelers by income level (low, average, and high) and trip purpose (work vs. personal trips), recognizing that different travelers value their time differently. Work trips typically have higher VOT since travel time directly impacts productivity, while personal trips reflect individuals’ willingness to trade time for money in their leisure activities.\nThis notebook replicates and updates the methodology from the archived Excel workbook, providing a transparent, reproducible workflow using open source data science tools."
  },
  {
    "objectID": "index.html#environment-setup",
    "href": "index.html#environment-setup",
    "title": "Value of Time Estimation",
    "section": "2 Environment Setup",
    "text": "2 Environment Setup\n\nInstall Required Packages\nThis section prepares the computing environment by loading necessary Python libraries and configuring project-specific settings. We use pandas and numpy for data manipulation, geopandas for spatial operations, and pygris for seamless access to Census data. The visualization libraries (matplotlib and seaborn) will help us understand income distributions and validate our calculations.\n!conda install -c conda-forge numpy pandas geopandas matplotlib seaborn python-dotenv openpyxl\n!pip install pygris\n\n\nLoad Libraries\nImport all required libraries for the analysis. The pygris library enables direct access to Census Bureau geographic data and ACS estimates through their API.\n\n\nShow the code\n# For Analysis\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport warnings\n\n# For Visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\nimport seaborn as sns\nfrom adjustText import adjust_text\n\n# Census data query libraries & modules\nfrom pygris import blocks, block_groups, counties, states\nfrom pygris.helpers import validate_state, validate_county\nfrom pygris.data import get_census\n\n# misc\nimport datetime\nimport os\nfrom pathlib import Path\nimport requests\n\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nFalse\n\n\n\n\nEnvironment Variables\nWe establish Utah-specific geographic parameters for the analysis. The NAD83 / UTM zone 12N coordinate reference system (EPSG:3566) is the standard projection for Utah, providing accurate distance measurements for spatial analysis. The state FIPS code (49) uniquely identifies Utah in federal datasets.\n\n\nShow the code\nPROJECT_CRS = \"EPSG:3566\"  # NAD83 / UTM zone 12N\nSTATE_FIPS = validate_state(\"UT\")\n\n\nUsing FIPS code '49' for input 'UT'\n\n\n\n\n\n\n\n\nTip\n\n\n\nNeed a Census API key? Get one for free at census.gov/developers.\nCreate a .env file in the project directory and add your Census API key: CENSUS_API_KEY=your-key-here This enables fetching US Census data from the Census API.\n\n\n\n\nShow the code\n# Set your API key into environment (alternative to .env file)\nos.environ['CENSUS_API_KEY'] = 'your_api_key_here'"
  },
  {
    "objectID": "index.html#define-helper-functions",
    "href": "index.html#define-helper-functions",
    "title": "Value of Time Estimation",
    "section": "3 Define Helper Functions",
    "text": "3 Define Helper Functions\nTo maintain code reusability and follow DRY (Don’t Repeat Yourself) principles, we define helper functions for common operations throughout the analysis.\n\nFetch Excel Files from BLS or BTS\nThis utility function automates downloading data files from federal agencies. It checks if a file already exists locally before attempting to download, avoiding unnecessary network requests and respecting the agencies’ servers. The function includes proper HTTP headers to ensure reliable downloads.\n\n\nShow the code\ndef fetch_excel(path, url):\n    \"\"\"\n    Download Excel file if it doesn't exist locally.\n\n    Parameters:\n    -----------\n    path : str or Path\n        Local file path to save the Excel file\n    url : str\n        URL to download the Excel file from\n    \"\"\"\n    # Convert to Path object if string\n    filepath = Path(path)\n\n    # Download file if it doesn't exist\n    if not filepath.exists():\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n        }\n\n        response = requests.get(url, headers=headers)\n        filepath.write_bytes(response.content)"
  },
  {
    "objectID": "index.html#lookup-tables",
    "href": "index.html#lookup-tables",
    "title": "Value of Time Estimation",
    "section": "4 Lookup Tables",
    "text": "4 Lookup Tables\nLookup tables serve as reference datasets that map categories to values. These tables ensure consistency across calculations and make the code more maintainable by centralizing key parameter definitions.\n\nIncome Category Lookup\nThe ACS reports household income in 16 predefined brackets rather than individual values. To perform calculations with this grouped data, we need to estimate representative income values for each bracket. This lookup table defines the boundaries of each income bracket and calculates midpoint values.\nFor the highest income bracket ($200,000+), which has no upper limit, we use $300,000 as a reasonable midpoint. This value is based on research showing that high-income distributions typically concentrate between $200,000 and $400,000, with $300,000 representing a conservative central estimate.Create a reference table defining the income brackets used in ACS Table B19001. Each bracket has a lower and upper limit, and we calculate midpoints for median estimation. The highest bracket ($200,000+) uses $300,000 as a reasonable midpoint based on income distribution patterns.\n\n\nShow the code\nlookup_hhinc = pd.DataFrame({\n  \"Income Category\": [\n    \"HH_LT_10K\", \"HH_10_15K\", \"HH_15_20K\", \"HH_20_25K\", \"HH_25_30K\", \"HH_30_35K\",\n    \"HH_35_40K\", \"HH_40_45K\", \"HH_45_50K\", \"HH_50_60K\", \"HH_60_75K\",\n    \"HH_75_100K\", \"HH_100_125K\", \"HH_125_150K\", \"HH_150_200K\", \"HH_GT_200K\"\n  ],\n  \"Lower Limit\": [\n    0, 10000, 15000, 20000, 25000, 30000,\n    35000, 40000, 45000, 50000, 60000,\n    75000, 100000, 125000, 150000, 200000\n  ],\n  \"Upper Limit\": [\n    9999, 14999, 19999, 24999, 29999, 34999,\n    39999, 44999, 49999, 59999, 74999,\n    99999, 124999, 149999, 199999, np.inf\n  ]\n})\n\n# Compute midpoint and round it\nlookup_hhinc['Midpoint'] = (\n  (lookup_hhinc['Lower Limit'] + lookup_hhinc['Upper Limit']) / 2\n).round()\n\n# Replace infinite midpoint (last category) with 300000\nlookup_hhinc.loc[np.isinf(lookup_hhinc[\"Upper Limit\"]), \"Midpoint\"] = 300000\n\nlookup_hhinc\n\n\n\n\n\n\n\n\n\nIncome Category\nLower Limit\nUpper Limit\nMidpoint\n\n\n\n\n0\nHH_LT_10K\n0\n9999.0\n5000.0\n\n\n1\nHH_10_15K\n10000\n14999.0\n12500.0\n\n\n2\nHH_15_20K\n15000\n19999.0\n17500.0\n\n\n3\nHH_20_25K\n20000\n24999.0\n22500.0\n\n\n4\nHH_25_30K\n25000\n29999.0\n27500.0\n\n\n5\nHH_30_35K\n30000\n34999.0\n32500.0\n\n\n6\nHH_35_40K\n35000\n39999.0\n37500.0\n\n\n7\nHH_40_45K\n40000\n44999.0\n42500.0\n\n\n8\nHH_45_50K\n45000\n49999.0\n47500.0\n\n\n9\nHH_50_60K\n50000\n59999.0\n55000.0\n\n\n10\nHH_60_75K\n60000\n74999.0\n67500.0\n\n\n11\nHH_75_100K\n75000\n99999.0\n87500.0\n\n\n12\nHH_100_125K\n100000\n124999.0\n112500.0\n\n\n13\nHH_125_150K\n125000\n149999.0\n137500.0\n\n\n14\nHH_150_200K\n150000\n199999.0\n175000.0\n\n\n15\nHH_GT_200K\n200000\ninf\n300000.0"
  },
  {
    "objectID": "index.html#raw-data-sources",
    "href": "index.html#raw-data-sources",
    "title": "Value of Time Estimation",
    "section": "5 Raw Data Sources",
    "text": "5 Raw Data Sources\nThis section retrieves the foundational datasets needed for VOT estimation. We access data directly from authoritative federal sources to ensure accuracy and reproducibility.\n\nConsumer Price Index\nThe CPI-U-RS (Consumer Price Index for All Urban Consumers - Research Series) provides the most consistent measure of inflation over time. While we use current-year dollars in this analysis, having CPI data available enables future inflation adjustments and facilitates comparisons with historical VOT estimates. The research series is specifically designed for longitudinal analysis, maintaining methodological consistency that the standard CPI-U lacks.\nData Source: Consumer Price Index for All Urban Consumers (CPI-U) [Source: Bureau of Labor Statistics]\n\n\nShow the code\n# Set file path and URL for CPI data\nfilepath_cpi = Path(\"_data/bls/r-cpi-u-rs-allitems.xlsx\")\nurl_cpi = \"https://www.bls.gov/cpi/research-series/r-cpi-u-rs-allitems.xlsx\"\n\n# Ensure the file exists, Download if not\nfetch_excel(path=filepath_cpi, url=url_cpi)\n\n# Read Excel file\ndf_CPI = pd.read_excel(\n    filepath_cpi,\n    sheet_name=\"All items\",\n    usecols=\"A:N\",\n    skiprows=5,\n    engine='openpyxl'\n)\n\ndf_CPI\n\n\n\n\n\n\n\n\n\nYEAR\nJAN\nFEB\nMAR\nAPR\nMAY\nJUNE\nJULY\nAUG\nSEP\nOCT\nNOV\nDEC\nAVG\n\n\n\n\n0\n1977\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n100.0\nNaN\n\n\n1\n1978\n100.5\n101.1\n101.8\n102.7\n103.6\n104.5\n105.0\n105.5\n106.1\n106.7\n107.3\n107.8\n104.4\n\n\n2\n1979\n108.7\n109.7\n110.7\n111.8\n113.0\n114.1\n115.1\n116.0\n117.1\n117.9\n118.5\n119.5\n114.3\n\n\n3\n1980\n120.8\n122.4\n123.8\n124.7\n125.7\n126.7\n127.5\n128.6\n129.9\n130.7\n131.5\n132.4\n127.1\n\n\n4\n1981\n133.6\n135.2\n136.3\n137.1\n137.9\n138.7\n139.7\n140.7\n141.8\n142.4\n142.9\n143.4\n139.1\n\n\n5\n1982\n144.2\n144.7\n144.9\n145.0\n146.1\n147.5\n148.5\n148.8\n149.5\n150.2\n150.5\n150.6\n147.5\n\n\n6\n1983\n151.0\n151.1\n151.2\n152.4\n153.2\n153.7\n154.3\n154.8\n155.6\n156.0\n156.1\n156.3\n153.8\n\n\n7\n1984\n157.2\n158.0\n158.3\n159.0\n159.5\n159.9\n160.4\n161.1\n161.8\n162.2\n162.2\n162.3\n160.2\n\n\n8\n1985\n162.5\n163.2\n163.9\n164.6\n165.2\n165.6\n165.9\n166.2\n166.8\n167.2\n167.7\n168.1\n165.6\n\n\n9\n1986\n168.6\n168.1\n167.3\n166.9\n167.4\n168.2\n168.2\n168.5\n169.4\n169.5\n169.5\n169.6\n168.4\n\n\n10\n1987\n170.6\n171.3\n172.0\n172.9\n173.4\n174.0\n174.3\n175.3\n176.1\n176.5\n176.6\n176.5\n174.1\n\n\n11\n1988\n177.0\n177.3\n178.0\n178.9\n179.5\n180.1\n180.8\n181.6\n182.7\n183.2\n183.3\n183.4\n180.5\n\n\n12\n1989\n184.3\n184.9\n185.9\n187.2\n188.1\n188.5\n189.0\n189.2\n189.8\n190.6\n190.9\n191.1\n188.3\n\n\n13\n1990\n193.0\n193.9\n194.9\n195.2\n195.5\n196.5\n197.3\n199.0\n200.6\n201.7\n202.0\n202.0\n197.6\n\n\n14\n1991\n202.9\n203.1\n203.3\n203.5\n204.1\n204.5\n204.7\n205.2\n206.1\n206.2\n206.7\n206.8\n204.8\n\n\n15\n1992\n207.2\n207.7\n208.6\n209.0\n209.3\n209.7\n210.1\n210.6\n211.2\n211.8\n212.1\n211.9\n209.9\n\n\n16\n1993\n212.6\n213.3\n214.0\n214.5\n215.0\n215.2\n215.3\n215.7\n216.0\n216.7\n216.9\n216.7\n215.2\n\n\n17\n1994\n217.1\n217.6\n218.4\n218.6\n218.9\n219.5\n220.0\n220.7\n221.1\n221.2\n221.5\n221.4\n219.7\n\n\n18\n1995\n222.2\n222.9\n223.6\n224.3\n224.7\n225.2\n225.3\n225.7\n226.1\n226.7\n226.5\n226.4\n225.0\n\n\n19\n1996\n227.5\n228.3\n229.4\n230.2\n230.8\n230.9\n231.3\n231.5\n232.3\n233.0\n233.4\n233.4\n231.0\n\n\n20\n1997\n234.1\n234.7\n235.2\n235.5\n235.4\n235.8\n235.9\n236.3\n237.1\n237.5\n237.4\n237.0\n236.0\n\n\n21\n1998\n237.4\n237.8\n238.1\n238.6\n239.0\n239.1\n239.4\n239.7\n240.0\n240.5\n240.5\n240.3\n239.2\n\n\n22\n1999\n240.9\n241.2\n241.9\n243.6\n243.6\n243.7\n244.4\n245.1\n246.2\n246.7\n246.8\n246.8\n244.2\n\n\n23\n2000\n247.6\n249.1\n251.1\n251.2\n251.4\n252.9\n253.4\n253.4\n254.8\n255.1\n255.3\n255.1\n252.5\n\n\n24\n2001\n256.8\n257.9\n258.5\n259.5\n260.5\n261.1\n260.3\n260.4\n261.4\n260.6\n260.1\n259.1\n259.7\n\n\n25\n2002\n259.8\n260.8\n262.2\n263.7\n263.6\n263.9\n264.1\n265.0\n265.4\n265.9\n265.9\n265.3\n263.8\n\n\n26\n2003\n266.4\n268.6\n270.2\n269.5\n269.1\n269.5\n269.7\n270.7\n271.6\n271.4\n270.6\n270.3\n269.8\n\n\n27\n2004\n271.7\n273.2\n274.9\n275.8\n277.3\n278.2\n277.8\n277.9\n278.5\n280.0\n280.2\n279.1\n277.0\n\n\n28\n2005\n279.6\n281.3\n283.5\n285.4\n285.2\n285.2\n286.5\n288.0\n291.5\n292.2\n289.8\n288.6\n286.4\n\n\n29\n2006\n290.8\n291.4\n293.1\n295.5\n296.9\n297.6\n298.4\n299.1\n297.6\n296.0\n295.6\n296.0\n295.7\n\n\n30\n2007\n296.9\n298.5\n301.2\n303.1\n305.0\n305.6\n305.5\n304.9\n305.8\n306.4\n308.3\n308.1\n304.1\n\n\n31\n2008\n309.6\n310.5\n313.2\n315.1\n317.7\n320.9\n322.6\n321.3\n320.9\n317.6\n311.6\n308.3\n315.8\n\n\n32\n2009\n309.7\n311.2\n312.0\n312.8\n313.7\n316.4\n315.8\n316.6\n316.8\n317.1\n317.3\n316.7\n314.7\n\n\n33\n2010\n317.8\n317.9\n319.2\n319.8\n320.0\n319.7\n319.8\n320.2\n320.4\n320.8\n320.9\n321.5\n319.8\n\n\n34\n2011\n323.0\n324.6\n327.8\n329.9\n331.5\n331.1\n331.4\n332.3\n332.8\n332.2\n331.9\n331.1\n330.0\n\n\n35\n2012\n332.6\n334.0\n336.6\n337.6\n337.2\n336.7\n336.2\n338.1\n339.6\n339.5\n337.9\n337.0\n336.9\n\n\n36\n2013\n338.0\n340.8\n341.7\n341.3\n341.9\n342.8\n342.9\n343.3\n343.8\n342.9\n342.2\n342.2\n342.0\n\n\n37\n2014\n343.5\n344.8\n347.0\n348.2\n349.4\n350.1\n349.9\n349.3\n349.6\n348.7\n346.9\n344.9\n347.7\n\n\n38\n2015\n343.4\n344.9\n346.9\n347.7\n349.4\n350.7\n350.7\n350.2\n349.7\n349.5\n348.8\n347.6\n348.3\n\n\n39\n2016\n348.2\n348.5\n350.0\n351.7\n353.1\n354.2\n353.7\n354.0\n354.8\n355.3\n354.7\n354.9\n352.8\n\n\n40\n2017\n356.9\n358.0\n358.3\n359.4\n359.7\n360.0\n359.8\n360.9\n362.8\n362.5\n362.6\n362.3\n360.3\n\n\n41\n2018\n364.3\n366.0\n366.7\n368.3\n369.8\n370.3\n370.4\n370.7\n371.1\n371.8\n370.6\n369.3\n369.1\n\n\n42\n2019\n370.0\n371.5\n373.6\n375.6\n376.4\n376.5\n377.2\n377.1\n377.5\n378.4\n378.2\n377.8\n375.8\n\n\n43\n2020\n379.2\n380.2\n379.5\n377.2\n377.2\n379.4\n381.3\n382.6\n383.1\n383.2\n382.9\n383.2\n380.8\n\n\n44\n2021\n384.9\n387.1\n390.0\n393.2\n396.7\n400.5\n402.4\n403.1\n404.2\n407.6\n409.5\n410.8\n399.2\n\n\n45\n2022\n414.3\n418.2\n423.9\n426.3\n431.0\n436.9\n436.8\n436.7\n437.6\n439.4\n439.0\n437.6\n431.5\n\n\n46\n2023\n441.1\n443.6\n445.0\n447.3\n448.4\n449.9\n450.7\n452.7\n453.8\n453.6\n452.7\n452.3\n449.3\n\n\n47\n2024\n454.7\n457.6\n460.5\n462.3\n463.1\n463.2\n463.8\n464.1\n464.9\n465.4\n465.2\n465.3\n462.5\n\n\n\n\n\n\n\nWhat we find: The CPI data shows the annual inflation rates that can be used to adjust income values across different time periods. For travel demand modeling, using inflation-adjusted dollars ensures that VOT parameters remain comparable over multi-year planning horizons.\n\n\nAmerican Community Survey (ACS) 5-Year Estimates\n\nDefine Census Variables\nThe ACS 5-Year Estimates provide the most reliable small-area income statistics available. Unlike the 1-Year estimates, which have large margins of error, the 5-year data aggregates five years of survey responses to produce stable estimates suitable for sub-state analysis. We extract data from two key tables:\n\nTable B19013: Median household income (direct estimate)\nTable B19001: Household count by income bracket (distribution)\n\nThe income brackets in B19001 align perfectly with our lookup table, allowing us to calculate weighted averages and validate the median income from B19013.\n\n\nShow the code\n# Define variables to download\nacs_variables = {\n    'B19013_001E': 'HH_MED_INC',  # Median Household Income in the Past 12 Months (in 2023 Inflation-Adjusted Dollars)\n    'B19013_001M': 'HH_MED_INC_MOE',  # Margin of Error for Median Household Income\n    'B19001_001E': 'HH_TOTAL',  # Total Households\n    'B19001_002E': 'HH_LT_10K',  # Less than $10,000\n    'B19001_003E': 'HH_10_15K',  # $10,000 to $14,999\n    'B19001_004E': 'HH_15_20K',  # $15,000 to $19,999\n    'B19001_005E': 'HH_20_25K',  # $20,000 to $24,999\n    'B19001_006E': 'HH_25_30K',  # $25,000 to $29,999\n    'B19001_007E': 'HH_30_35K',  # $30,000 to $34,999\n    'B19001_008E': 'HH_35_40K',  # $35,000 to $39,999\n    'B19001_009E': 'HH_40_45K',  # $40,000 to $44,999\n    'B19001_010E': 'HH_45_50K',  # $45,000 to $49,999\n    'B19001_011E': 'HH_50_60K',  # $50,000 to $59,999\n    'B19001_012E': 'HH_60_75K',  # $60,000 to $74,999\n    'B19001_013E': 'HH_75_100K',  # $75,000 to $99,999\n    'B19001_014E': 'HH_100_125K',  # $100,000 to $124,999\n    'B19001_015E': 'HH_125_150K',  # $125,000 to $149,999\n    'B19001_016E': 'HH_150_200K',  # $150,000 to $199,999\n    'B19001_017E': 'HH_GT_200K'  # $200,000 or more\n}\n\n\n\n\nState Level Data\nWe begin with state-level data for Utah to establish baseline income statistics. While our final VOT parameters may use more granular geographic data in the future, state-level estimates provide a robust foundation with minimal sampling error. The large sample size at the state level ensures that our calculated VOT parameters are statistically reliable.\n\n\nShow the code\n# Fetch state boundaries from TIGER/Line shapefiles\ngdf_ut_bound = states(\n  year=2023,\n  cache=True\n).to_crs(PROJECT_CRS)\n\n# Filter for Utah only\ngdf_ut_bound = gdf_ut_bound[gdf_ut_bound['STATEFP'] == str(STATE_FIPS)]\n\n# Fetch Income data from ACS 5-year estimates for Utah\ndf_ut_income = get_census(\n  dataset=\"acs/acs5\",\n  year=2023,\n  variables=list(acs_variables.keys()),\n  params={\n      # \"key\": f\"{os.getenv('CENSUS_API_KEY')}\", # FIXME: This causes error\n      \"for\": f\"state:{STATE_FIPS}\"\n    },\n    return_geoid=True,\n    guess_dtypes=True\n)\n\n# Join ACS data to block group boundaries and transform CRS\ngdf_ut_income = gdf_ut_bound[['GEOID', 'STATEFP', 'NAME', 'geometry']].merge(\n    df_ut_income, on = \"GEOID\"\n).to_crs(PROJECT_CRS).rename(columns=acs_variables)\n\n# Preview data\ngdf_ut_income\n\n\n\n\n\n\n\n\n\nGEOID\nSTATEFP\nNAME\ngeometry\nHH_MED_INC\nHH_MED_INC_MOE\nHH_TOTAL\nHH_LT_10K\nHH_10_15K\nHH_15_20K\n...\nHH_35_40K\nHH_40_45K\nHH_45_50K\nHH_50_60K\nHH_60_75K\nHH_75_100K\nHH_100_125K\nHH_125_150K\nHH_150_200K\nHH_GT_200K\n\n\n\n\n0\n49\n49\nUtah\nPOLYGON ((900313.399 6302435.171, 900580.099 6...\n91750\n634\n1094896\n33918\n22999\n22352\n...\n33072\n32113\n35150\n69627\n104883\n159368\n134089\n102926\n124090\n137560\n\n\n\n\n1 rows × 23 columns\n\n\n\nWhat we find: Utah’s median household income from the ACS provides the anchor point for all subsequent calculations. The distribution across income brackets shows the shape of Utah’s income distribution, which typically differs from national patterns due to the state’s unique demographic characteristics (larger household sizes, younger population, and specific economic structure)."
  },
  {
    "objectID": "index.html#intermediate-calculations",
    "href": "index.html#intermediate-calculations",
    "title": "Value of Time Estimation",
    "section": "6 Intermediate Calculations",
    "text": "6 Intermediate Calculations\nWith raw data in hand, we now perform the intermediate calculations needed to derive VOT parameters. These steps transform income distributions into the specific metrics required by the travel demand model.\n\nIncome Groupings (Approximate Income Quartiles)\nTravel demand models often segment travelers by income level because income strongly influences mode choice, route selection, and willingness to pay for time savings. Rather than using 16 separate income categories (which would create excessive model complexity), we aggregate households into four income groups approximating quartiles.\nThe quartile approach ensures that each income group contains roughly 25% of households, providing balanced sample sizes for model estimation. However, because ACS income brackets don’t align perfectly with quartile boundaries, we assign entire brackets to the quartile they predominantly fall within.\nIncome Group 1 (Low Income): The first quartile of households by income. This group typically has the lowest VOT because they face tighter budget constraints and may be more willing to spend time to save money.\nIncome Groups 2-4 (Higher Income): The upper three quartiles, which we sometimes aggregate as “high income” in contrast to the lowest quartile. These households generally have higher VOT because their opportunity cost of time is greater.\n\n\nShow the code\n# Create a copy of lookup table to work with\ndf_inc_group = lookup_hhinc.copy()\n\n# Get the income category columns from gdf_ut_income\n# Extract just the income bracket counts (excluding totals and medians)\nincome_cols = [col for col in gdf_ut_income.columns if col.startswith('HH_')\n               and col not in ['HH_TOTAL', 'HH_MED_INC', 'HH_MED_INC_MOE']]\n\n# Create a mapping between lookup categories and gdf_ut_income columns\n# They should already match, but let's be explicit\ndf_inc_group['State HH'] = df_inc_group['Income Category'].map(\n    gdf_ut_income[income_cols].iloc[0].to_dict()\n)\n\n# Calculate percentage of households\ntotal_hh = df_inc_group['State HH'].sum()\ndf_inc_group['% HH'] = (df_inc_group['State HH'] / total_hh * 100).round(1)\n\n# Calculate cumulative percentage\ndf_inc_group['Cum % HH'] = df_inc_group['% HH'].cumsum().round(1)\n\n# Assign income groups based on quartiles (25%, 50%, 75%, 100%)\ndf_inc_group['Inc Group'] = pd.cut(\n    df_inc_group['Cum % HH'],\n    bins=[0, 25, 50, 75, 100],\n    labels=['Inc Group 1', 'Inc Group 2', 'Inc Group 3', 'Inc Group 4'],\n    include_lowest=True\n)\n\n# Calculate HH_MedInc_Product (HH * Midpoint)\ndf_inc_group['HH_MedInc_Product'] = df_inc_group['State HH'] * df_inc_group['Midpoint']\n\n# Display the dataframe\ndf_inc_group\n\n\n\n\n\n\n\n\n\nIncome Category\nLower Limit\nUpper Limit\nMidpoint\nState HH\n% HH\nCum % HH\nInc Group\nHH_MedInc_Product\n\n\n\n\n0\nHH_LT_10K\n0\n9999.0\n5000.0\n33918\n3.1\n3.1\nInc Group 1\n1.695900e+08\n\n\n1\nHH_10_15K\n10000\n14999.0\n12500.0\n22999\n2.1\n5.2\nInc Group 1\n2.874875e+08\n\n\n2\nHH_15_20K\n15000\n19999.0\n17500.0\n22352\n2.0\n7.2\nInc Group 1\n3.911600e+08\n\n\n3\nHH_20_25K\n20000\n24999.0\n22500.0\n24376\n2.2\n9.4\nInc Group 1\n5.484600e+08\n\n\n4\nHH_25_30K\n25000\n29999.0\n27500.0\n28040\n2.6\n12.0\nInc Group 1\n7.711000e+08\n\n\n5\nHH_30_35K\n30000\n34999.0\n32500.0\n30333\n2.8\n14.8\nInc Group 1\n9.858225e+08\n\n\n6\nHH_35_40K\n35000\n39999.0\n37500.0\n33072\n3.0\n17.8\nInc Group 1\n1.240200e+09\n\n\n7\nHH_40_45K\n40000\n44999.0\n42500.0\n32113\n2.9\n20.7\nInc Group 1\n1.364802e+09\n\n\n8\nHH_45_50K\n45000\n49999.0\n47500.0\n35150\n3.2\n23.9\nInc Group 1\n1.669625e+09\n\n\n9\nHH_50_60K\n50000\n59999.0\n55000.0\n69627\n6.4\n30.3\nInc Group 2\n3.829485e+09\n\n\n10\nHH_60_75K\n60000\n74999.0\n67500.0\n104883\n9.6\n39.9\nInc Group 2\n7.079602e+09\n\n\n11\nHH_75_100K\n75000\n99999.0\n87500.0\n159368\n14.6\n54.5\nInc Group 3\n1.394470e+10\n\n\n12\nHH_100_125K\n100000\n124999.0\n112500.0\n134089\n12.2\n66.7\nInc Group 3\n1.508501e+10\n\n\n13\nHH_125_150K\n125000\n149999.0\n137500.0\n102926\n9.4\n76.1\nInc Group 4\n1.415232e+10\n\n\n14\nHH_150_200K\n150000\n199999.0\n175000.0\n124090\n11.3\n87.4\nInc Group 4\n2.171575e+10\n\n\n15\nHH_GT_200K\n200000\ninf\n300000.0\n137560\n12.6\n100.0\nInc Group 4\n4.126800e+10\n\n\n\n\n\n\n\n\n\nShow the code\n# Prepare data for seaborn\ndf_plot = df_inc_group.copy()\ndf_plot['Income Label'] = df_plot['Income Category'].str.replace('HH_', '').str.replace('_', ' - ')\ndf_plot['index'] = range(len(df_plot))\n\n# Define colors for each income group\npalette = {'Inc Group 1': '#3498db', 'Inc Group 2': '#2ecc71',\n           'Inc Group 3': '#f39c12', 'Inc Group 4': '#e74c3c'}\n\n# Set seaborn style and context\nsns.set_style(\"whitegrid\")\nsns.set_context(\"notebook\")\n\n# Create barplot using seaborn\n# plt.figure(figsize=(12, 6))\nsns.barplot(\n    data=df_plot,\n    x='index',\n    y='State HH',\n    hue='Inc Group',\n    palette=palette,\n    legend=True,\n    dodge=False\n)\n\n# Customize plot\nplt.xlabel('Income Category', fontsize=11, fontweight='bold')\nplt.ylabel('Number of Households', fontsize=11, fontweight='bold')\nplt.title('Utah Household Income Distribution by Quartile',\n          fontsize=13, fontweight='bold', pad=20)\n\n# Format y-axis with comma separator\nplt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n\n# Set x-axis labels\nplt.xticks(range(len(df_plot)), df_plot['Income Label'],\n           rotation=45, ha='right', fontsize=9)\n\n# Customize legend\nplt.legend(loc='upper left', frameon=True, fontsize=10, title='')\n\n# Grid styling\nplt.grid(axis='y', alpha=0.3, linestyle='--')\nplt.gca().set_axisbelow(True)\n\n# Remove top and right spines for cleaner look\nsns.despine()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nHousehold Income Distribution by Quartile\n\n\n\n\nWhat we find: The visualization reveals Utah’s income distribution shape. We see a concentration of households in middle-income brackets with smaller tails at the lower extreme. This indicates a relatively strong middle class. The quartile assignments allow us to create a simplified four-group segmentation suitable for model implementation while preserving the essential income-based variation in time values.\n\n\nMedian Income (in Model Base Year Dollars)\nTo calculate VOT, we need a single representative income value for each income segment. The median is preferable to the mean because it’s less sensitive to extreme values and better represents the “typical” household in each group.\nWe calculate medians using two approaches:\n\nWeighted average of bracket midpoints: Using our lookup table midpoints and household counts\nACS-reported median: The direct estimate from Table B19013\n\nThe weighted average approach typically produces a value slightly different from the ACS median due to our simplified midpoint assumptions. We calculate a correction factor to align our estimates with the official ACS median for the full population, then apply this same correction proportionally to the income group medians. This ensures internal consistency while respecting the authoritative ACS estimates.\n\n\nShow the code\n# Define income categories\ncategories = {\n    'Average': df_inc_group,\n    'Low Inc': df_inc_group[df_inc_group['Inc Group'] == 'Inc Group 1'],\n    'High Inc': df_inc_group[df_inc_group['Inc Group'] != 'Inc Group 1']\n}\n\n# Calculate metrics for each category\nsummary_data = {}\nfor cat_name, cat_df in categories.items():\n    summary_data[cat_name] = {\n        'Sum HH': cat_df['State HH'].sum(),\n        'Sum HH * Inc': cat_df['HH_MedInc_Product'].sum(),\n    }\n    # Calculate unadjusted median income\n    summary_data[cat_name]['Unadj Med Inc'] = (\n        summary_data[cat_name]['Sum HH * Inc'] / summary_data[cat_name]['Sum HH']\n    )\n\n# Calculate correction factor from Average category\nactual_median_income = gdf_ut_income['HH_MED_INC'].iloc[0]\ncorrection_factor = actual_median_income / summary_data['Average']['Unadj Med Inc']\ninflation_factor = 1.0\n\n# Apply correction and inflation factors\nfor cat_name in summary_data:\n    summary_data[cat_name]['Correction Factor'] = correction_factor\n    summary_data[cat_name]['Adj Med Income'] = (\n        summary_data[cat_name]['Unadj Med Inc'] * correction_factor\n    )\n    summary_data[cat_name]['Inflation Adj Factor'] = inflation_factor\n    summary_data[cat_name]['Median Income'] = (\n        summary_data[cat_name]['Adj Med Income'] * inflation_factor\n    )\n\n# Convert to DataFrame\ndf_summary = pd.DataFrame(summary_data).T\n\n# Format for display\nformat_specs = {\n    'Sum HH': '{:,.0f}',\n    'Sum HH * Inc': '{:,.0f}',\n    'Unadj Med Inc': '${:,.0f}',\n    'Correction Factor': '{:.4f}',\n    'Adj Med Income': '${:,.0f}',\n    'Inflation Adj Factor': '{:.4f}',\n    'Median Income': '${:,.0f}'\n}\n\ndf_median_income = df_summary.copy()\nfor col, fmt in format_specs.items():\n    df_median_income[col] = df_summary[col].apply(lambda x: fmt.format(x))\n\ndf_median_income\n\n\n\n\n\n\n\n\n\nSum HH\nSum HH * Inc\nUnadj Med Inc\nCorrection Factor\nAdj Med Income\nInflation Adj Factor\nMedian Income\n\n\n\n\nAverage\n1,094,896\n124,503,122,500\n$113,712\n0.8069\n$91,750\n1.0000\n$91,750\n\n\nLow Inc\n262,353\n7,428,247,500\n$28,314\n0.8069\n$22,845\n1.0000\n$22,845\n\n\nHigh Inc\n832,543\n117,074,875,000\n$140,623\n0.8069\n$113,463\n1.0000\n$113,463\n\n\n\n\n\n\n\nWhat we find:\n\nAverage Median Income: The overall median for all Utah households, matching the ACS B19013 estimate\nLow Income Median: The median for the bottom quartile, representing lower-wage workers, retirees on fixed incomes, and households with part-time employment\nHigh Income Median: The median for the upper three quartiles combined, representing professional workers, dual-income households, and higher-wage earners\n\nThese three values form the foundation for calculating income-differentiated VOT parameters.\n\n\nValue of Time (in Model Base Year Dollars)\nThe Value of Time converts annual income into an hourly rate, then applies purpose-specific multipliers to reflect how travelers trade off time and money for different trip types. The fundamental assumption is that VOT relates to income—higher earners value time more—but the relationship isn’t one-to-one.\nResearch from revealed preference studies (toll usage patterns) and stated preference surveys consistently shows that:\n\nPeople value work trip time at 35-50% of their wage rate (employers care about productivity, commuters care about stress and lost leisure)\nPeople value personal trip time at 25-35% of their wage rate (pure leisure trade-off)\nCommercial vehicles have higher VOT reflecting business operating costs beyond driver wages\n\nThe percentages we apply come from regional travel behavior studies, calibrated to match observed patterns in toll lane usage, route choice, and mode choice behavior.\n\nCalculate Hourly Income\nWe convert annual median income to an hourly rate by dividing by 2,080 hours (52 weeks × 40 hours/week). This assumes full-time, year-round employment, which is a standard convention in VOT estimation. While not every household member works full-time, this standardization allows consistent comparison across income groups and aligns with how wages are typically expressed.\n\n\nShow the code\n# Convert annual median income to hourly rate (assuming 2080 work hours/year)\ndf_hourly = pd.DataFrame({\n    'Median Income': df_summary['Median Income'],\n    'Hourly Rate': df_summary['Median Income'] / 2080\n}, index=['Average', 'Low Inc', 'High Inc'])\n\ndf_hourly.style.format({\n    'Median Income': '${:,.0f}',\n    'Hourly Rate': '${:.2f}'\n})\n\n\n\n\n\n\n\n \nMedian Income\nHourly Rate\n\n\n\n\nAverage\n$91,750\n$44.11\n\n\nLow Inc\n$22,845\n$10.98\n\n\nHigh Inc\n$113,463\n$54.55\n\n\n\n\n\nWhat we find: The hourly rates provide an intuitive way to think about the opportunity cost of time. For example, if the average household has an hourly rate of $45, spending an hour in traffic has a notional cost of $45 in lost productive time or leisure.\n\n\nCalculate VOT in cents per mile\nThese hardcoded percentages represent the fraction of hourly wage that travelers implicitly value their travel time at, based on observed behavior in previous studies. The percentages differ by trip purpose because:\nWork Trips (higher %): Include both the opportunity cost to the traveler AND the employer’s interest in worker productivity. However, it’s typically less than 100% of the wage because commute time is partially compensated through location choice (people choose home/work locations balancing commute time against housing costs and wages).\nPersonal Trips (lower %): Reflect pure leisure time trade-offs. People are willing to spend more time traveling when they have flexibility and the marginal utility of saved time is lower.\nIncome Effects: Lower-income travelers often show higher VOT as a percentage of income for work trips (they can’t afford to be late) but lower for personal trips (more time-flexible). Higher-income travelers show the opposite pattern.\n\n\n\n\n\n\nImportant\n\n\n\nThese percentages have been calibrated in previous model validation efforts to match observed behavior patterns in the region.\n\n\n\n\nShow the code\n# Define VOT as percentage of hourly income for each trip purpose and income group\n# Hardcoded VOT percentages from previous calculations\nvot_pct = pd.DataFrame({\n    'Work': [0.39, 0.62, 0.34],\n    'Personal': [0.30, 0.49, 0.27]\n}, index=['Average', 'Low Inc', 'High Inc'])\n\n\n\n\nShow the code\n# Calculate VOT in cents per minute (hourly rate * percentage * 100 / 60)\nvot_cents_min = ((df_hourly['Hourly Rate'].values[:, None] * vot_pct) * 100 / 60).round(0)\n\nvot_cents_min.style.format({\n    'Work': '${:.1f}',\n    'Personal': '${:.1f}'\n})\n\n\n\n\n\n\n\n \nWork\nPersonal\n\n\n\n\nAverage\n$29.0\n$22.0\n\n\nLow Inc\n$11.0\n$9.0\n\n\nHigh Inc\n$31.0\n$25.0\n\n\n\n\n\n\n\nCalculate and Display Work & Personal VOT\nWe now calculate the final VOT values in cents per minute, the standard unit for travel demand models. The conversion from dollars per hour to cents per minute (multiplying by 100, dividing by 60) makes the values easier to work with in network assignment algorithms where travel times are typically in minutes.\nWork VOT Results: These values represent how much travelers implicitly pay (in toll charges, fuel costs, or inconvenience) to save one minute of travel time on work-related trips. Higher-income travelers have higher work VOT, reflecting both their higher opportunity cost and their greater ability to pay for time savings.\n\n\nShow the code\n# Display Work VOT results\ndf_vot_work = pd.DataFrame({\n    '% of Income': vot_pct['Work'],\n    'Unrounded ($/hr)': df_hourly['Hourly Rate'] * vot_pct['Work'],\n    'VOT (¢/min)': vot_cents_min['Work'],\n    'Equivalent ($/hr)': vot_cents_min['Work'] * 60 / 100\n}, index=['Average', 'Low Inc', 'High Inc'])\n\ndf_vot_work.style.format({\n    '% of Income': '{:.0%}',\n    'Unrounded ($/hr)': '${:.2f}',\n    'VOT (¢/min)': '{:.0f}',\n    'Equivalent ($/hr)': '${:.2f}'\n})\n\n\n\n\n\n\n\n \n% of Income\nUnrounded ($/hr)\nVOT (¢/min)\nEquivalent ($/hr)\n\n\n\n\nAverage\n39%\n$17.20\n29\n$17.40\n\n\nLow Inc\n62%\n$6.81\n11\n$6.60\n\n\nHigh Inc\n34%\n$18.55\n31\n$18.60\n\n\n\n\n\nPersonal VOT Results: Personal trip VOT is consistently lower than work VOT across all income groups. The relative difference between income groups is also more pronounced, as higher-income households have more discretionary income to trade for leisure time convenience.\n\n\nShow the code\n# Display Personal VOT results\ndf_vot_personal = pd.DataFrame({\n    '% of Income': vot_pct['Personal'],\n    'Unrounded ($/hr)': df_hourly['Hourly Rate'] * vot_pct['Personal'],\n    'VOT (¢/min)': vot_cents_min['Personal'],\n    'Equivalent ($/hr)': vot_cents_min['Personal'] * 60 / 100\n}, index=['Average', 'Low Inc', 'High Inc'])\n\ndf_vot_personal.style.format({\n    '% of Income': '{:.0%}',\n    'Unrounded ($/hr)': '${:.2f}',\n    'VOT (¢/min)': '{:.0f}',\n    'Equivalent ($/hr)': '${:.2f}'\n})\n\n\n\n\n\n\n\n \n% of Income\nUnrounded ($/hr)\nVOT (¢/min)\nEquivalent ($/hr)\n\n\n\n\nAverage\n30%\n$13.23\n22\n$13.20\n\n\nLow Inc\n49%\n$5.38\n9\n$5.40\n\n\nHigh Inc\n27%\n$14.73\n25\n$15.00\n\n\n\n\n\nModel Application: These VOT values feed directly into the mode choice and route choice components of the travel demand model. For example, if a toll road saves 10 minutes compared to a free alternative, a traveler will choose the toll road if the toll cost is less than (10 minutes × VOT). The model predicts what fraction of travelers find the trade-off worthwhile based on their income segment and trip purpose distribution.\n\n\nCalculate and Display Truck VOT\nCommercial vehicle VOT requires a different framework than passenger vehicles because it reflects business operating costs rather than personal wage rates. Truck VOT includes:\n\nDriver wages and benefits\nVehicle operating costs (fuel, maintenance, depreciation)\nCargo value and time-sensitivity\nBusiness overhead and profit margins\n\nThe percentages (relative to average household income) are calibrated to match observed commercial vehicle behavior, particularly toll road usage patterns. Larger trucks have higher VOT because they carry more valuable cargo, have higher operating costs per hour, and typically serve time-sensitive delivery schedules.\nTruck Categories:\n\nLight Trucks: Small commercial vehicles, delivery vans, service vehicles\nMedium Trucks: Box trucks, small semi-trailers, regional delivery vehicles\nHeavy Trucks: Large semi-trailers, long-haul freight, bulk cargo carriers\n\n\n\n\n\n\n\nImportant\n\n\n\nThese percentages have been calibrated in previous model validation efforts to match observed behavior patterns in the region.\n\n\n\n\nShow the code\n# Calculate Truck VOT (using Average income as base)\ntruck_pct = pd.Series([0.65, 0.87, 1.10], index=['Light', 'Medium', 'Heavy'])\n\n\n\n\nShow the code\ndf_vot_trucks = pd.DataFrame({\n    '% of Income': truck_pct,\n    'Unrounded ($/hr)': df_hourly.loc['Average', 'Hourly Rate'] * truck_pct,\n    'VOT (¢/min)': ((df_hourly.loc['Average', 'Hourly Rate'] * truck_pct) * 100 / 60).round(0)\n})\n\ndf_vot_trucks['Equivalent ($/hr)'] = df_vot_trucks['VOT (¢/min)'] * 60 / 100\n\ndf_vot_trucks.style.format({\n    '% of Income': '{:.0%}',\n    'Unrounded ($/hr)': '${:.2f}',\n    'VOT (¢/min)': '{:.0f}',\n    'Equivalent ($/hr)': '${:.2f}'\n})\n\n\n\n\n\n\n\n \n% of Income\nUnrounded ($/hr)\nVOT (¢/min)\nEquivalent ($/hr)\n\n\n\n\nLight\n65%\n$28.67\n48\n$28.80\n\n\nMedium\n87%\n$38.38\n64\n$38.40\n\n\nHeavy\n110%\n$48.52\n81\n$48.60\n\n\n\n\n\nWhat we find: Heavy truck VOT can exceed $30/hour, reflecting the high cost of keeping valuable cargo and expensive equipment idle in traffic. This high VOT explains why commercial vehicles disproportionately use toll facilities and why freight routing is highly sensitive to congestion and travel time reliability."
  },
  {
    "objectID": "index.html#export-results",
    "href": "index.html#export-results",
    "title": "Value of Time Estimation",
    "section": "7 Export Results",
    "text": "7 Export Results\nThe final step packages our calculated VOT parameters in formats ready for model implementation and documentation.\n\nCreate Final VOT Table\nThis table assembles all VOT parameters into a single reference dataset matching the travel demand model’s naming conventions. Each parameter corresponds to a specific traveler type and trip purpose combination:\nParameter Definitions:\n\nVOT_Auto_Wrk: Standard work trip VOT (average income)\nVOT_Auto_Per: Standard personal trip VOT (average income)\nVOT_Auto_Ext: External trips (average of work and personal, used for through-trips)\nVOT_LT, VOT_MD, VOT_HV: Light, medium, and heavy truck VOT\nVOT_Auto_Wrk_Lo, VOT_Auto_Per_Lo: Low-income work and personal trip VOT\nVOT_Auto_Wrk_Hi, VOT_Auto_Per_Hi: High-income work and personal trip VOT\n\nThe table displays values in both cents per minute (for model input) and dollars per hour (for intuitive interpretation).\n\n\nShow the code\n# Build the final VOT parameters table\ndf_vot_params = pd.DataFrame({\n    'Parameter': [\n        'VOT_Auto_Wrk', 'VOT_Auto_Per', 'VOT_Auto_Ext',\n        'VOT_LT', 'VOT_MD', 'VOT_HV',\n        'VOT_Auto_Wrk_Lo', 'VOT_Auto_Per_Lo',\n        'VOT_Auto_Wrk_Hi', 'VOT_Auto_Per_Hi'\n    ],\n    'VOT (cent/min)': [\n        vot_cents_min.loc['Average', 'Work'],\n        vot_cents_min.loc['Average', 'Personal'],\n        (vot_cents_min.loc['Average', 'Work'] + vot_cents_min.loc['Average', 'Personal']) / 2,\n        df_vot_trucks.loc['Light', 'VOT (¢/min)'],\n        df_vot_trucks.loc['Medium', 'VOT (¢/min)'],\n        df_vot_trucks.loc['Heavy', 'VOT (¢/min)'],\n        vot_cents_min.loc['Low Inc', 'Work'],\n        vot_cents_min.loc['Low Inc', 'Personal'],\n        vot_cents_min.loc['High Inc', 'Work'],\n        vot_cents_min.loc['High Inc', 'Personal']\n    ]\n})\n\ndf_vot_params['VOT ($/hr)'] = df_vot_params['VOT (cent/min)'] * 60 / 100\n\ndf_vot_params.style.format({\n    'VOT (cent/min)': '{:.0f}¢',\n    'VOT ($/hr)': '${:.1f}'\n})\n\n\n\n\n\n\n\n \nParameter\nVOT (cent/min)\nVOT ($/hr)\n\n\n\n\n0\nVOT_Auto_Wrk\n29¢\n$17.4\n\n\n1\nVOT_Auto_Per\n22¢\n$13.2\n\n\n2\nVOT_Auto_Ext\n26¢\n$15.3\n\n\n3\nVOT_LT\n48¢\n$28.8\n\n\n4\nVOT_MD\n64¢\n$38.4\n\n\n5\nVOT_HV\n81¢\n$48.6\n\n\n6\nVOT_Auto_Wrk_Lo\n11¢\n$6.6\n\n\n7\nVOT_Auto_Per_Lo\n9¢\n$5.4\n\n\n8\nVOT_Auto_Wrk_Hi\n31¢\n$18.6\n\n\n9\nVOT_Auto_Per_Hi\n25¢\n$15.0\n\n\n\n\n\n\n\nExport to CSV\nWe export the final VOT parameters to a CSV file for easy integration into the travel demand model configuration. This file becomes the authoritative source for VOT parameters, documenting the values used in model runs and providing traceability back to the source data and methodology.\n\n\nShow the code\n# Create output directory if it doesn't exist\noutput_dir = Path(\"_output\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Export to CSV\ndf_vot_params.to_csv(\n    output_dir / \"value_of_time.csv\",\n    index=False\n)\n\n\nThe exported file can be version-controlled alongside the model, ensuring that any changes to VOT assumptions are tracked and documented. When updating the model to new base years or recalibrating with new income data, this notebook can be re-run to generate updated VOT parameters consistently.\n\n\n\n\n\n\nTipDownload the output files:\n\n\n\nvalue_of_time.csv"
  }
]