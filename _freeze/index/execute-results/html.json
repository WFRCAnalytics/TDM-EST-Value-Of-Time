{
  "hash": "bf78d87266024fa91851d03f096be9c3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Value of Time Estimation\nsubtitle: Estimating the Value of Time (VOT) Parameter for Utah's Travel Demand Model\ndescription: This notebook replicates the analysis from the '_archive/_Source - Med Income & Value of Time - 2022-08-09.xlsb' using the Utah Household and Hosehold Income data from 2019-2023 American Community Survey 5-Year Estimates. The VOTs are segmented by occupancy and purpose (work vs. personal).\nauthor:\n - name: Pukar Bhandari\n   email: pukar.bhandari@wfrc.utah.gov\n   affiliation:\n     - name: Wasatch Front Regional Council\n       url: \"https://wfrc.utah.gov/\"\ndate: \"2025-10-14\"\n---\n\n## Introduction\n\nThis analysis estimates the Value of Time (VOT) parameters for Utah's travel demand model using income data from the American Community Survey (ACS) 2019-2023 5-Year Estimates. The VOT represents how much travelers value their time, expressed in cents per minute, and is a critical parameter for evaluating transportation projects and predicting mode choice behavior.\n\nThe methodology segments travelers by income level (low, average, and high) and trip purpose (work vs. personal trips), recognizing that different travelers value their time differently. Work trips typically have higher VOT since travel time directly impacts productivity, while personal trips reflect individuals' willingness to trade time for money in their leisure activities.\n\nThis notebook replicates and updates the methodology from the archived Excel workbook, providing a transparent, reproducible workflow using open source data science tools.\n\n## Environment Setup\n\n### Install Required Packages\n\nThis section prepares the computing environment by loading necessary Python libraries and configuring project-specific settings. We use pandas and numpy for data manipulation, geopandas for spatial operations, and pygris for seamless access to Census data. The visualization libraries (matplotlib and seaborn) will help us understand income distributions and validate our calculations.\n\n``` python\n!conda install -c conda-forge numpy pandas geopandas matplotlib seaborn python-dotenv openpyxl\n!pip install pygris\n```\n\n### Load Libraries\n\nImport all required libraries for the analysis. The pygris library enables direct access to Census Bureau geographic data and ACS estimates through their API.\n\n::: {#1973fc87 .cell execution_count=1}\n``` {.python .cell-code}\n# For Analysis\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport warnings\n\n# For Visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\nimport seaborn as sns\nfrom adjustText import adjust_text\n\n# Census data query libraries & modules\nfrom pygris import blocks, block_groups, counties, states\nfrom pygris.helpers import validate_state, validate_county\nfrom pygris.data import get_census\n\n# misc\nimport datetime\nimport os\nfrom pathlib import Path\nimport requests\n\nfrom dotenv import load_dotenv\nload_dotenv()\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\nFalse\n```\n:::\n:::\n\n\n### Environment Variables\n\nWe establish Utah-specific geographic parameters for the analysis. The NAD83 / UTM zone 12N coordinate reference system (EPSG:3566) is the standard projection for Utah, providing accurate distance measurements for spatial analysis. The state FIPS code (49) uniquely identifies Utah in federal datasets.\n\n::: {#dcbc90e0 .cell execution_count=2}\n``` {.python .cell-code}\nPROJECT_CRS = \"EPSG:3566\"  # NAD83 / UTM zone 12N\nSTATE_FIPS = validate_state(\"UT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUsing FIPS code '49' for input 'UT'\n```\n:::\n:::\n\n\n::: {.callout-tip}\n**Need a Census API key?** Get one for free at [census.gov/developers](https://api.census.gov/data/key_signup.html).\n\nCreate a `.env` file in the project directory and add your Census API key:\n```CENSUS_API_KEY=your-key-here```\nThis enables fetching US Census data from the Census API.\n:::\n\n::: {#94e25454 .cell execution_count=3}\n``` {.python .cell-code}\n# Set your API key into environment (alternative to .env file)\nos.environ['CENSUS_API_KEY'] = 'your_api_key_here'\n```\n:::\n\n\n## Define Helper Functions\n\nTo maintain code reusability and follow DRY (Don't Repeat Yourself) principles, we define helper functions for common operations throughout the analysis.\n\n### Fetch Excel Files from BLS or BTS\n\nThis utility function automates downloading data files from federal agencies. It checks if a file already exists locally before attempting to download, avoiding unnecessary network requests and respecting the agencies' servers. The function includes proper HTTP headers to ensure reliable downloads.\n\n::: {#99446945 .cell execution_count=4}\n``` {.python .cell-code}\ndef fetch_excel(path, url):\n    \"\"\"\n    Download Excel file if it doesn't exist locally.\n\n    Parameters:\n    -----------\n    path : str or Path\n        Local file path to save the Excel file\n    url : str\n        URL to download the Excel file from\n    \"\"\"\n    # Convert to Path object if string\n    filepath = Path(path)\n\n    # Download file if it doesn't exist\n    if not filepath.exists():\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        headers = {\n            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n        }\n\n        response = requests.get(url, headers=headers)\n        filepath.write_bytes(response.content)\n```\n:::\n\n\n## Lookup Tables\n\nLookup tables serve as reference datasets that map categories to values. These tables ensure consistency across calculations and make the code more maintainable by centralizing key parameter definitions.\n\n### Income Category Lookup\n\nThe ACS reports household income in 16 predefined brackets rather than individual values. To perform calculations with this grouped data, we need to estimate representative income values for each bracket. This lookup table defines the boundaries of each income bracket and calculates midpoint values.\n\nFor the highest income bracket ($200,000+), which has no upper limit, we use $300,000 as a reasonable midpoint. This value is based on research showing that high-income distributions typically concentrate between $200,000 and $400,000, with $300,000 representing a conservative central estimate.Create a reference table defining the income brackets used in ACS Table B19001. Each bracket has a lower and upper limit, and we calculate midpoints for median estimation. The highest bracket ($200,000+) uses $300,000 as a reasonable midpoint based on income distribution patterns.\n\n::: {#62547acc .cell execution_count=5}\n``` {.python .cell-code}\nlookup_hhinc = pd.DataFrame({\n  \"Income Category\": [\n    \"HH_LT_10K\", \"HH_10_15K\", \"HH_15_20K\", \"HH_20_25K\", \"HH_25_30K\", \"HH_30_35K\",\n    \"HH_35_40K\", \"HH_40_45K\", \"HH_45_50K\", \"HH_50_60K\", \"HH_60_75K\",\n    \"HH_75_100K\", \"HH_100_125K\", \"HH_125_150K\", \"HH_150_200K\", \"HH_GT_200K\"\n  ],\n  \"Lower Limit\": [\n    0, 10000, 15000, 20000, 25000, 30000,\n    35000, 40000, 45000, 50000, 60000,\n    75000, 100000, 125000, 150000, 200000\n  ],\n  \"Upper Limit\": [\n    9999, 14999, 19999, 24999, 29999, 34999,\n    39999, 44999, 49999, 59999, 74999,\n    99999, 124999, 149999, 199999, np.inf\n  ]\n})\n\n# Compute midpoint and round it\nlookup_hhinc['Midpoint'] = (\n  (lookup_hhinc['Lower Limit'] + lookup_hhinc['Upper Limit']) / 2\n).round()\n\n# Replace infinite midpoint (last category) with 300000\nlookup_hhinc.loc[np.isinf(lookup_hhinc[\"Upper Limit\"]), \"Midpoint\"] = 300000\n\nlookup_hhinc\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income Category</th>\n      <th>Lower Limit</th>\n      <th>Upper Limit</th>\n      <th>Midpoint</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HH_LT_10K</td>\n      <td>0</td>\n      <td>9999.0</td>\n      <td>5000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HH_10_15K</td>\n      <td>10000</td>\n      <td>14999.0</td>\n      <td>12500.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HH_15_20K</td>\n      <td>15000</td>\n      <td>19999.0</td>\n      <td>17500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HH_20_25K</td>\n      <td>20000</td>\n      <td>24999.0</td>\n      <td>22500.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HH_25_30K</td>\n      <td>25000</td>\n      <td>29999.0</td>\n      <td>27500.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HH_30_35K</td>\n      <td>30000</td>\n      <td>34999.0</td>\n      <td>32500.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>HH_35_40K</td>\n      <td>35000</td>\n      <td>39999.0</td>\n      <td>37500.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HH_40_45K</td>\n      <td>40000</td>\n      <td>44999.0</td>\n      <td>42500.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>HH_45_50K</td>\n      <td>45000</td>\n      <td>49999.0</td>\n      <td>47500.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HH_50_60K</td>\n      <td>50000</td>\n      <td>59999.0</td>\n      <td>55000.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>HH_60_75K</td>\n      <td>60000</td>\n      <td>74999.0</td>\n      <td>67500.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>HH_75_100K</td>\n      <td>75000</td>\n      <td>99999.0</td>\n      <td>87500.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>HH_100_125K</td>\n      <td>100000</td>\n      <td>124999.0</td>\n      <td>112500.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>HH_125_150K</td>\n      <td>125000</td>\n      <td>149999.0</td>\n      <td>137500.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>HH_150_200K</td>\n      <td>150000</td>\n      <td>199999.0</td>\n      <td>175000.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>HH_GT_200K</td>\n      <td>200000</td>\n      <td>inf</td>\n      <td>300000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Raw Data Sources\n\nThis section retrieves the foundational datasets needed for VOT estimation. We access data directly from authoritative federal sources to ensure accuracy and reproducibility.\n\n### Consumer Price Index\n\nThe CPI-U-RS (Consumer Price Index for All Urban Consumers - Research Series) provides the most consistent measure of inflation over time. While we use current-year dollars in this analysis, having CPI data available enables future inflation adjustments and facilitates comparisons with historical VOT estimates. The research series is specifically designed for longitudinal analysis, maintaining methodological consistency that the standard CPI-U lacks.\n\nData Source: Consumer Price Index for All Urban Consumers (CPI-U) \\[Source: [Bureau of Labor Statistics](https://www.bls.gov/cpi/research-series/r-cpi-u-rs-home.htm)\\]\n\n::: {#67b5ceba .cell execution_count=6}\n``` {.python .cell-code}\n# Set file path and URL for CPI data\nfilepath_cpi = Path(\"_data/bls/r-cpi-u-rs-allitems.xlsx\")\nurl_cpi = \"https://www.bls.gov/cpi/research-series/r-cpi-u-rs-allitems.xlsx\"\n\n# Ensure the file exists, Download if not\nfetch_excel(path=filepath_cpi, url=url_cpi)\n\n# Read Excel file\ndf_CPI = pd.read_excel(\n    filepath_cpi,\n    sheet_name=\"All items\",\n    usecols=\"A:N\",\n    skiprows=5,\n    engine='openpyxl'\n)\n\ndf_CPI\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YEAR</th>\n      <th>JAN</th>\n      <th>FEB</th>\n      <th>MAR</th>\n      <th>APR</th>\n      <th>MAY</th>\n      <th>JUNE</th>\n      <th>JULY</th>\n      <th>AUG</th>\n      <th>SEP</th>\n      <th>OCT</th>\n      <th>NOV</th>\n      <th>DEC</th>\n      <th>AVG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1977</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1978</td>\n      <td>100.5</td>\n      <td>101.1</td>\n      <td>101.8</td>\n      <td>102.7</td>\n      <td>103.6</td>\n      <td>104.5</td>\n      <td>105.0</td>\n      <td>105.5</td>\n      <td>106.1</td>\n      <td>106.7</td>\n      <td>107.3</td>\n      <td>107.8</td>\n      <td>104.4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979</td>\n      <td>108.7</td>\n      <td>109.7</td>\n      <td>110.7</td>\n      <td>111.8</td>\n      <td>113.0</td>\n      <td>114.1</td>\n      <td>115.1</td>\n      <td>116.0</td>\n      <td>117.1</td>\n      <td>117.9</td>\n      <td>118.5</td>\n      <td>119.5</td>\n      <td>114.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1980</td>\n      <td>120.8</td>\n      <td>122.4</td>\n      <td>123.8</td>\n      <td>124.7</td>\n      <td>125.7</td>\n      <td>126.7</td>\n      <td>127.5</td>\n      <td>128.6</td>\n      <td>129.9</td>\n      <td>130.7</td>\n      <td>131.5</td>\n      <td>132.4</td>\n      <td>127.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1981</td>\n      <td>133.6</td>\n      <td>135.2</td>\n      <td>136.3</td>\n      <td>137.1</td>\n      <td>137.9</td>\n      <td>138.7</td>\n      <td>139.7</td>\n      <td>140.7</td>\n      <td>141.8</td>\n      <td>142.4</td>\n      <td>142.9</td>\n      <td>143.4</td>\n      <td>139.1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1982</td>\n      <td>144.2</td>\n      <td>144.7</td>\n      <td>144.9</td>\n      <td>145.0</td>\n      <td>146.1</td>\n      <td>147.5</td>\n      <td>148.5</td>\n      <td>148.8</td>\n      <td>149.5</td>\n      <td>150.2</td>\n      <td>150.5</td>\n      <td>150.6</td>\n      <td>147.5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1983</td>\n      <td>151.0</td>\n      <td>151.1</td>\n      <td>151.2</td>\n      <td>152.4</td>\n      <td>153.2</td>\n      <td>153.7</td>\n      <td>154.3</td>\n      <td>154.8</td>\n      <td>155.6</td>\n      <td>156.0</td>\n      <td>156.1</td>\n      <td>156.3</td>\n      <td>153.8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1984</td>\n      <td>157.2</td>\n      <td>158.0</td>\n      <td>158.3</td>\n      <td>159.0</td>\n      <td>159.5</td>\n      <td>159.9</td>\n      <td>160.4</td>\n      <td>161.1</td>\n      <td>161.8</td>\n      <td>162.2</td>\n      <td>162.2</td>\n      <td>162.3</td>\n      <td>160.2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1985</td>\n      <td>162.5</td>\n      <td>163.2</td>\n      <td>163.9</td>\n      <td>164.6</td>\n      <td>165.2</td>\n      <td>165.6</td>\n      <td>165.9</td>\n      <td>166.2</td>\n      <td>166.8</td>\n      <td>167.2</td>\n      <td>167.7</td>\n      <td>168.1</td>\n      <td>165.6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1986</td>\n      <td>168.6</td>\n      <td>168.1</td>\n      <td>167.3</td>\n      <td>166.9</td>\n      <td>167.4</td>\n      <td>168.2</td>\n      <td>168.2</td>\n      <td>168.5</td>\n      <td>169.4</td>\n      <td>169.5</td>\n      <td>169.5</td>\n      <td>169.6</td>\n      <td>168.4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1987</td>\n      <td>170.6</td>\n      <td>171.3</td>\n      <td>172.0</td>\n      <td>172.9</td>\n      <td>173.4</td>\n      <td>174.0</td>\n      <td>174.3</td>\n      <td>175.3</td>\n      <td>176.1</td>\n      <td>176.5</td>\n      <td>176.6</td>\n      <td>176.5</td>\n      <td>174.1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1988</td>\n      <td>177.0</td>\n      <td>177.3</td>\n      <td>178.0</td>\n      <td>178.9</td>\n      <td>179.5</td>\n      <td>180.1</td>\n      <td>180.8</td>\n      <td>181.6</td>\n      <td>182.7</td>\n      <td>183.2</td>\n      <td>183.3</td>\n      <td>183.4</td>\n      <td>180.5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1989</td>\n      <td>184.3</td>\n      <td>184.9</td>\n      <td>185.9</td>\n      <td>187.2</td>\n      <td>188.1</td>\n      <td>188.5</td>\n      <td>189.0</td>\n      <td>189.2</td>\n      <td>189.8</td>\n      <td>190.6</td>\n      <td>190.9</td>\n      <td>191.1</td>\n      <td>188.3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1990</td>\n      <td>193.0</td>\n      <td>193.9</td>\n      <td>194.9</td>\n      <td>195.2</td>\n      <td>195.5</td>\n      <td>196.5</td>\n      <td>197.3</td>\n      <td>199.0</td>\n      <td>200.6</td>\n      <td>201.7</td>\n      <td>202.0</td>\n      <td>202.0</td>\n      <td>197.6</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1991</td>\n      <td>202.9</td>\n      <td>203.1</td>\n      <td>203.3</td>\n      <td>203.5</td>\n      <td>204.1</td>\n      <td>204.5</td>\n      <td>204.7</td>\n      <td>205.2</td>\n      <td>206.1</td>\n      <td>206.2</td>\n      <td>206.7</td>\n      <td>206.8</td>\n      <td>204.8</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1992</td>\n      <td>207.2</td>\n      <td>207.7</td>\n      <td>208.6</td>\n      <td>209.0</td>\n      <td>209.3</td>\n      <td>209.7</td>\n      <td>210.1</td>\n      <td>210.6</td>\n      <td>211.2</td>\n      <td>211.8</td>\n      <td>212.1</td>\n      <td>211.9</td>\n      <td>209.9</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1993</td>\n      <td>212.6</td>\n      <td>213.3</td>\n      <td>214.0</td>\n      <td>214.5</td>\n      <td>215.0</td>\n      <td>215.2</td>\n      <td>215.3</td>\n      <td>215.7</td>\n      <td>216.0</td>\n      <td>216.7</td>\n      <td>216.9</td>\n      <td>216.7</td>\n      <td>215.2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1994</td>\n      <td>217.1</td>\n      <td>217.6</td>\n      <td>218.4</td>\n      <td>218.6</td>\n      <td>218.9</td>\n      <td>219.5</td>\n      <td>220.0</td>\n      <td>220.7</td>\n      <td>221.1</td>\n      <td>221.2</td>\n      <td>221.5</td>\n      <td>221.4</td>\n      <td>219.7</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1995</td>\n      <td>222.2</td>\n      <td>222.9</td>\n      <td>223.6</td>\n      <td>224.3</td>\n      <td>224.7</td>\n      <td>225.2</td>\n      <td>225.3</td>\n      <td>225.7</td>\n      <td>226.1</td>\n      <td>226.7</td>\n      <td>226.5</td>\n      <td>226.4</td>\n      <td>225.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1996</td>\n      <td>227.5</td>\n      <td>228.3</td>\n      <td>229.4</td>\n      <td>230.2</td>\n      <td>230.8</td>\n      <td>230.9</td>\n      <td>231.3</td>\n      <td>231.5</td>\n      <td>232.3</td>\n      <td>233.0</td>\n      <td>233.4</td>\n      <td>233.4</td>\n      <td>231.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1997</td>\n      <td>234.1</td>\n      <td>234.7</td>\n      <td>235.2</td>\n      <td>235.5</td>\n      <td>235.4</td>\n      <td>235.8</td>\n      <td>235.9</td>\n      <td>236.3</td>\n      <td>237.1</td>\n      <td>237.5</td>\n      <td>237.4</td>\n      <td>237.0</td>\n      <td>236.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1998</td>\n      <td>237.4</td>\n      <td>237.8</td>\n      <td>238.1</td>\n      <td>238.6</td>\n      <td>239.0</td>\n      <td>239.1</td>\n      <td>239.4</td>\n      <td>239.7</td>\n      <td>240.0</td>\n      <td>240.5</td>\n      <td>240.5</td>\n      <td>240.3</td>\n      <td>239.2</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1999</td>\n      <td>240.9</td>\n      <td>241.2</td>\n      <td>241.9</td>\n      <td>243.6</td>\n      <td>243.6</td>\n      <td>243.7</td>\n      <td>244.4</td>\n      <td>245.1</td>\n      <td>246.2</td>\n      <td>246.7</td>\n      <td>246.8</td>\n      <td>246.8</td>\n      <td>244.2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2000</td>\n      <td>247.6</td>\n      <td>249.1</td>\n      <td>251.1</td>\n      <td>251.2</td>\n      <td>251.4</td>\n      <td>252.9</td>\n      <td>253.4</td>\n      <td>253.4</td>\n      <td>254.8</td>\n      <td>255.1</td>\n      <td>255.3</td>\n      <td>255.1</td>\n      <td>252.5</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2001</td>\n      <td>256.8</td>\n      <td>257.9</td>\n      <td>258.5</td>\n      <td>259.5</td>\n      <td>260.5</td>\n      <td>261.1</td>\n      <td>260.3</td>\n      <td>260.4</td>\n      <td>261.4</td>\n      <td>260.6</td>\n      <td>260.1</td>\n      <td>259.1</td>\n      <td>259.7</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2002</td>\n      <td>259.8</td>\n      <td>260.8</td>\n      <td>262.2</td>\n      <td>263.7</td>\n      <td>263.6</td>\n      <td>263.9</td>\n      <td>264.1</td>\n      <td>265.0</td>\n      <td>265.4</td>\n      <td>265.9</td>\n      <td>265.9</td>\n      <td>265.3</td>\n      <td>263.8</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2003</td>\n      <td>266.4</td>\n      <td>268.6</td>\n      <td>270.2</td>\n      <td>269.5</td>\n      <td>269.1</td>\n      <td>269.5</td>\n      <td>269.7</td>\n      <td>270.7</td>\n      <td>271.6</td>\n      <td>271.4</td>\n      <td>270.6</td>\n      <td>270.3</td>\n      <td>269.8</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2004</td>\n      <td>271.7</td>\n      <td>273.2</td>\n      <td>274.9</td>\n      <td>275.8</td>\n      <td>277.3</td>\n      <td>278.2</td>\n      <td>277.8</td>\n      <td>277.9</td>\n      <td>278.5</td>\n      <td>280.0</td>\n      <td>280.2</td>\n      <td>279.1</td>\n      <td>277.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2005</td>\n      <td>279.6</td>\n      <td>281.3</td>\n      <td>283.5</td>\n      <td>285.4</td>\n      <td>285.2</td>\n      <td>285.2</td>\n      <td>286.5</td>\n      <td>288.0</td>\n      <td>291.5</td>\n      <td>292.2</td>\n      <td>289.8</td>\n      <td>288.6</td>\n      <td>286.4</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2006</td>\n      <td>290.8</td>\n      <td>291.4</td>\n      <td>293.1</td>\n      <td>295.5</td>\n      <td>296.9</td>\n      <td>297.6</td>\n      <td>298.4</td>\n      <td>299.1</td>\n      <td>297.6</td>\n      <td>296.0</td>\n      <td>295.6</td>\n      <td>296.0</td>\n      <td>295.7</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2007</td>\n      <td>296.9</td>\n      <td>298.5</td>\n      <td>301.2</td>\n      <td>303.1</td>\n      <td>305.0</td>\n      <td>305.6</td>\n      <td>305.5</td>\n      <td>304.9</td>\n      <td>305.8</td>\n      <td>306.4</td>\n      <td>308.3</td>\n      <td>308.1</td>\n      <td>304.1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2008</td>\n      <td>309.6</td>\n      <td>310.5</td>\n      <td>313.2</td>\n      <td>315.1</td>\n      <td>317.7</td>\n      <td>320.9</td>\n      <td>322.6</td>\n      <td>321.3</td>\n      <td>320.9</td>\n      <td>317.6</td>\n      <td>311.6</td>\n      <td>308.3</td>\n      <td>315.8</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2009</td>\n      <td>309.7</td>\n      <td>311.2</td>\n      <td>312.0</td>\n      <td>312.8</td>\n      <td>313.7</td>\n      <td>316.4</td>\n      <td>315.8</td>\n      <td>316.6</td>\n      <td>316.8</td>\n      <td>317.1</td>\n      <td>317.3</td>\n      <td>316.7</td>\n      <td>314.7</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2010</td>\n      <td>317.8</td>\n      <td>317.9</td>\n      <td>319.2</td>\n      <td>319.8</td>\n      <td>320.0</td>\n      <td>319.7</td>\n      <td>319.8</td>\n      <td>320.2</td>\n      <td>320.4</td>\n      <td>320.8</td>\n      <td>320.9</td>\n      <td>321.5</td>\n      <td>319.8</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2011</td>\n      <td>323.0</td>\n      <td>324.6</td>\n      <td>327.8</td>\n      <td>329.9</td>\n      <td>331.5</td>\n      <td>331.1</td>\n      <td>331.4</td>\n      <td>332.3</td>\n      <td>332.8</td>\n      <td>332.2</td>\n      <td>331.9</td>\n      <td>331.1</td>\n      <td>330.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2012</td>\n      <td>332.6</td>\n      <td>334.0</td>\n      <td>336.6</td>\n      <td>337.6</td>\n      <td>337.2</td>\n      <td>336.7</td>\n      <td>336.2</td>\n      <td>338.1</td>\n      <td>339.6</td>\n      <td>339.5</td>\n      <td>337.9</td>\n      <td>337.0</td>\n      <td>336.9</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2013</td>\n      <td>338.0</td>\n      <td>340.8</td>\n      <td>341.7</td>\n      <td>341.3</td>\n      <td>341.9</td>\n      <td>342.8</td>\n      <td>342.9</td>\n      <td>343.3</td>\n      <td>343.8</td>\n      <td>342.9</td>\n      <td>342.2</td>\n      <td>342.2</td>\n      <td>342.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2014</td>\n      <td>343.5</td>\n      <td>344.8</td>\n      <td>347.0</td>\n      <td>348.2</td>\n      <td>349.4</td>\n      <td>350.1</td>\n      <td>349.9</td>\n      <td>349.3</td>\n      <td>349.6</td>\n      <td>348.7</td>\n      <td>346.9</td>\n      <td>344.9</td>\n      <td>347.7</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2015</td>\n      <td>343.4</td>\n      <td>344.9</td>\n      <td>346.9</td>\n      <td>347.7</td>\n      <td>349.4</td>\n      <td>350.7</td>\n      <td>350.7</td>\n      <td>350.2</td>\n      <td>349.7</td>\n      <td>349.5</td>\n      <td>348.8</td>\n      <td>347.6</td>\n      <td>348.3</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2016</td>\n      <td>348.2</td>\n      <td>348.5</td>\n      <td>350.0</td>\n      <td>351.7</td>\n      <td>353.1</td>\n      <td>354.2</td>\n      <td>353.7</td>\n      <td>354.0</td>\n      <td>354.8</td>\n      <td>355.3</td>\n      <td>354.7</td>\n      <td>354.9</td>\n      <td>352.8</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>2017</td>\n      <td>356.9</td>\n      <td>358.0</td>\n      <td>358.3</td>\n      <td>359.4</td>\n      <td>359.7</td>\n      <td>360.0</td>\n      <td>359.8</td>\n      <td>360.9</td>\n      <td>362.8</td>\n      <td>362.5</td>\n      <td>362.6</td>\n      <td>362.3</td>\n      <td>360.3</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2018</td>\n      <td>364.3</td>\n      <td>366.0</td>\n      <td>366.7</td>\n      <td>368.3</td>\n      <td>369.8</td>\n      <td>370.3</td>\n      <td>370.4</td>\n      <td>370.7</td>\n      <td>371.1</td>\n      <td>371.8</td>\n      <td>370.6</td>\n      <td>369.3</td>\n      <td>369.1</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2019</td>\n      <td>370.0</td>\n      <td>371.5</td>\n      <td>373.6</td>\n      <td>375.6</td>\n      <td>376.4</td>\n      <td>376.5</td>\n      <td>377.2</td>\n      <td>377.1</td>\n      <td>377.5</td>\n      <td>378.4</td>\n      <td>378.2</td>\n      <td>377.8</td>\n      <td>375.8</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>2020</td>\n      <td>379.2</td>\n      <td>380.2</td>\n      <td>379.5</td>\n      <td>377.2</td>\n      <td>377.2</td>\n      <td>379.4</td>\n      <td>381.3</td>\n      <td>382.6</td>\n      <td>383.1</td>\n      <td>383.2</td>\n      <td>382.9</td>\n      <td>383.2</td>\n      <td>380.8</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>2021</td>\n      <td>384.9</td>\n      <td>387.1</td>\n      <td>390.0</td>\n      <td>393.2</td>\n      <td>396.7</td>\n      <td>400.5</td>\n      <td>402.4</td>\n      <td>403.1</td>\n      <td>404.2</td>\n      <td>407.6</td>\n      <td>409.5</td>\n      <td>410.8</td>\n      <td>399.2</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>2022</td>\n      <td>414.3</td>\n      <td>418.2</td>\n      <td>423.9</td>\n      <td>426.3</td>\n      <td>431.0</td>\n      <td>436.9</td>\n      <td>436.8</td>\n      <td>436.7</td>\n      <td>437.6</td>\n      <td>439.4</td>\n      <td>439.0</td>\n      <td>437.6</td>\n      <td>431.5</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2023</td>\n      <td>441.1</td>\n      <td>443.6</td>\n      <td>445.0</td>\n      <td>447.3</td>\n      <td>448.4</td>\n      <td>449.9</td>\n      <td>450.7</td>\n      <td>452.7</td>\n      <td>453.8</td>\n      <td>453.6</td>\n      <td>452.7</td>\n      <td>452.3</td>\n      <td>449.3</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>2024</td>\n      <td>454.7</td>\n      <td>457.6</td>\n      <td>460.5</td>\n      <td>462.3</td>\n      <td>463.1</td>\n      <td>463.2</td>\n      <td>463.8</td>\n      <td>464.1</td>\n      <td>464.9</td>\n      <td>465.4</td>\n      <td>465.2</td>\n      <td>465.3</td>\n      <td>462.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**What we find:** The CPI data shows the annual inflation rates that can be used to adjust income values across different time periods. For travel demand modeling, using inflation-adjusted dollars ensures that VOT parameters remain comparable over multi-year planning horizons.\n\n### American Community Survey (ACS) 5-Year Estimates\n\n#### Define Census Variables\n\nThe ACS 5-Year Estimates provide the most reliable small-area income statistics available. Unlike the 1-Year estimates, which have large margins of error, the 5-year data aggregates five years of survey responses to produce stable estimates suitable for sub-state analysis. We extract data from two key tables:\n\n- **Table B19013**: Median household income (direct estimate)\n- **Table B19001**: Household count by income bracket (distribution)\n\nThe income brackets in B19001 align perfectly with our lookup table, allowing us to calculate weighted averages and validate the median income from B19013.\n\n::: {#28e99966 .cell execution_count=7}\n``` {.python .cell-code}\n# Define variables to download\nacs_variables = {\n    'B19013_001E': 'HH_MED_INC',  # Median Household Income in the Past 12 Months (in 2023 Inflation-Adjusted Dollars)\n    'B19013_001M': 'HH_MED_INC_MOE',  # Margin of Error for Median Household Income\n    'B19001_001E': 'HH_TOTAL',  # Total Households\n    'B19001_002E': 'HH_LT_10K',  # Less than $10,000\n    'B19001_003E': 'HH_10_15K',  # $10,000 to $14,999\n    'B19001_004E': 'HH_15_20K',  # $15,000 to $19,999\n    'B19001_005E': 'HH_20_25K',  # $20,000 to $24,999\n    'B19001_006E': 'HH_25_30K',  # $25,000 to $29,999\n    'B19001_007E': 'HH_30_35K',  # $30,000 to $34,999\n    'B19001_008E': 'HH_35_40K',  # $35,000 to $39,999\n    'B19001_009E': 'HH_40_45K',  # $40,000 to $44,999\n    'B19001_010E': 'HH_45_50K',  # $45,000 to $49,999\n    'B19001_011E': 'HH_50_60K',  # $50,000 to $59,999\n    'B19001_012E': 'HH_60_75K',  # $60,000 to $74,999\n    'B19001_013E': 'HH_75_100K',  # $75,000 to $99,999\n    'B19001_014E': 'HH_100_125K',  # $100,000 to $124,999\n    'B19001_015E': 'HH_125_150K',  # $125,000 to $149,999\n    'B19001_016E': 'HH_150_200K',  # $150,000 to $199,999\n    'B19001_017E': 'HH_GT_200K'  # $200,000 or more\n}\n```\n:::\n\n\n#### State Level Data\n\nWe begin with state-level data for Utah to establish baseline income statistics. While our final VOT parameters may use more granular geographic data in the future, state-level estimates provide a robust foundation with minimal sampling error. The large sample size at the state level ensures that our calculated VOT parameters are statistically reliable.\n\n::: {#77c091a4 .cell execution_count=8}\n``` {.python .cell-code}\n# Fetch state boundaries from TIGER/Line shapefiles\ngdf_ut_bound = states(\n  year=2023,\n  cache=True\n).to_crs(PROJECT_CRS)\n\n# Filter for Utah only\ngdf_ut_bound = gdf_ut_bound[gdf_ut_bound['STATEFP'] == str(STATE_FIPS)]\n\n# Fetch Income data from ACS 5-year estimates for Utah\ndf_ut_income = get_census(\n  dataset=\"acs/acs5\",\n  year=2023,\n  variables=list(acs_variables.keys()),\n  params={\n      # \"key\": f\"{os.getenv('CENSUS_API_KEY')}\", # FIXME: This causes error\n      \"for\": f\"state:{STATE_FIPS}\"\n    },\n    return_geoid=True,\n    guess_dtypes=True\n)\n\n# Join ACS data to block group boundaries and transform CRS\ngdf_ut_income = gdf_ut_bound[['GEOID', 'STATEFP', 'NAME', 'geometry']].merge(\n    df_ut_income, on = \"GEOID\"\n).to_crs(PROJECT_CRS).rename(columns=acs_variables)\n\n# Preview data\ngdf_ut_income\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GEOID</th>\n      <th>STATEFP</th>\n      <th>NAME</th>\n      <th>geometry</th>\n      <th>HH_MED_INC</th>\n      <th>HH_MED_INC_MOE</th>\n      <th>HH_TOTAL</th>\n      <th>HH_LT_10K</th>\n      <th>HH_10_15K</th>\n      <th>HH_15_20K</th>\n      <th>...</th>\n      <th>HH_35_40K</th>\n      <th>HH_40_45K</th>\n      <th>HH_45_50K</th>\n      <th>HH_50_60K</th>\n      <th>HH_60_75K</th>\n      <th>HH_75_100K</th>\n      <th>HH_100_125K</th>\n      <th>HH_125_150K</th>\n      <th>HH_150_200K</th>\n      <th>HH_GT_200K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>49</td>\n      <td>49</td>\n      <td>Utah</td>\n      <td>POLYGON ((900313.399 6302435.171, 900580.099 6...</td>\n      <td>91750</td>\n      <td>634</td>\n      <td>1094896</td>\n      <td>33918</td>\n      <td>22999</td>\n      <td>22352</td>\n      <td>...</td>\n      <td>33072</td>\n      <td>32113</td>\n      <td>35150</td>\n      <td>69627</td>\n      <td>104883</td>\n      <td>159368</td>\n      <td>134089</td>\n      <td>102926</td>\n      <td>124090</td>\n      <td>137560</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>\n```\n:::\n:::\n\n\n**What we find:** Utah's median household income from the ACS provides the anchor point for all subsequent calculations. The distribution across income brackets shows the shape of Utah's income distribution, which typically differs from national patterns due to the state's unique demographic characteristics (larger household sizes, younger population, and specific economic structure).\n\n## Intermediate Calculations\n\nWith raw data in hand, we now perform the intermediate calculations needed to derive VOT parameters. These steps transform income distributions into the specific metrics required by the travel demand model.\n\n### Income Groupings (Approximate Income Quartiles)\n\nTravel demand models often segment travelers by income level because income strongly influences mode choice, route selection, and willingness to pay for time savings. Rather than using 16 separate income categories (which would create excessive model complexity), we aggregate households into four income groups approximating quartiles.\n\nThe quartile approach ensures that each income group contains roughly 25% of households, providing balanced sample sizes for model estimation. However, because ACS income brackets don't align perfectly with quartile boundaries, we assign entire brackets to the quartile they predominantly fall within.\n\n**Income Group 1 (Low Income)**: The first quartile of households by income. This group typically has the lowest VOT because they face tighter budget constraints and may be more willing to spend time to save money.\n\n**Income Groups 2-4 (Higher Income)**: The upper three quartiles, which we sometimes aggregate as \"high income\" in contrast to the lowest quartile. These households generally have higher VOT because their opportunity cost of time is greater.\n\n::: {#1faea24e .cell execution_count=9}\n``` {.python .cell-code}\n# Create a copy of lookup table to work with\ndf_inc_group = lookup_hhinc.copy()\n\n# Get the income category columns from gdf_ut_income\n# Extract just the income bracket counts (excluding totals and medians)\nincome_cols = [col for col in gdf_ut_income.columns if col.startswith('HH_')\n               and col not in ['HH_TOTAL', 'HH_MED_INC', 'HH_MED_INC_MOE']]\n\n# Create a mapping between lookup categories and gdf_ut_income columns\n# They should already match, but let's be explicit\ndf_inc_group['State HH'] = df_inc_group['Income Category'].map(\n    gdf_ut_income[income_cols].iloc[0].to_dict()\n)\n\n# Calculate percentage of households\ntotal_hh = df_inc_group['State HH'].sum()\ndf_inc_group['% HH'] = (df_inc_group['State HH'] / total_hh * 100).round(1)\n\n# Calculate cumulative percentage\ndf_inc_group['Cum % HH'] = df_inc_group['% HH'].cumsum().round(1)\n\n# Assign income groups based on quartiles (25%, 50%, 75%, 100%)\ndf_inc_group['Inc Group'] = pd.cut(\n    df_inc_group['Cum % HH'],\n    bins=[0, 25, 50, 75, 100],\n    labels=['Inc Group 1', 'Inc Group 2', 'Inc Group 3', 'Inc Group 4'],\n    include_lowest=True\n)\n\n# Calculate HH_MedInc_Product (HH * Midpoint)\ndf_inc_group['HH_MedInc_Product'] = df_inc_group['State HH'] * df_inc_group['Midpoint']\n\n# Display the dataframe\ndf_inc_group\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Income Category</th>\n      <th>Lower Limit</th>\n      <th>Upper Limit</th>\n      <th>Midpoint</th>\n      <th>State HH</th>\n      <th>% HH</th>\n      <th>Cum % HH</th>\n      <th>Inc Group</th>\n      <th>HH_MedInc_Product</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HH_LT_10K</td>\n      <td>0</td>\n      <td>9999.0</td>\n      <td>5000.0</td>\n      <td>33918</td>\n      <td>3.1</td>\n      <td>3.1</td>\n      <td>Inc Group 1</td>\n      <td>1.695900e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HH_10_15K</td>\n      <td>10000</td>\n      <td>14999.0</td>\n      <td>12500.0</td>\n      <td>22999</td>\n      <td>2.1</td>\n      <td>5.2</td>\n      <td>Inc Group 1</td>\n      <td>2.874875e+08</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HH_15_20K</td>\n      <td>15000</td>\n      <td>19999.0</td>\n      <td>17500.0</td>\n      <td>22352</td>\n      <td>2.0</td>\n      <td>7.2</td>\n      <td>Inc Group 1</td>\n      <td>3.911600e+08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HH_20_25K</td>\n      <td>20000</td>\n      <td>24999.0</td>\n      <td>22500.0</td>\n      <td>24376</td>\n      <td>2.2</td>\n      <td>9.4</td>\n      <td>Inc Group 1</td>\n      <td>5.484600e+08</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HH_25_30K</td>\n      <td>25000</td>\n      <td>29999.0</td>\n      <td>27500.0</td>\n      <td>28040</td>\n      <td>2.6</td>\n      <td>12.0</td>\n      <td>Inc Group 1</td>\n      <td>7.711000e+08</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>HH_30_35K</td>\n      <td>30000</td>\n      <td>34999.0</td>\n      <td>32500.0</td>\n      <td>30333</td>\n      <td>2.8</td>\n      <td>14.8</td>\n      <td>Inc Group 1</td>\n      <td>9.858225e+08</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>HH_35_40K</td>\n      <td>35000</td>\n      <td>39999.0</td>\n      <td>37500.0</td>\n      <td>33072</td>\n      <td>3.0</td>\n      <td>17.8</td>\n      <td>Inc Group 1</td>\n      <td>1.240200e+09</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>HH_40_45K</td>\n      <td>40000</td>\n      <td>44999.0</td>\n      <td>42500.0</td>\n      <td>32113</td>\n      <td>2.9</td>\n      <td>20.7</td>\n      <td>Inc Group 1</td>\n      <td>1.364802e+09</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>HH_45_50K</td>\n      <td>45000</td>\n      <td>49999.0</td>\n      <td>47500.0</td>\n      <td>35150</td>\n      <td>3.2</td>\n      <td>23.9</td>\n      <td>Inc Group 1</td>\n      <td>1.669625e+09</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>HH_50_60K</td>\n      <td>50000</td>\n      <td>59999.0</td>\n      <td>55000.0</td>\n      <td>69627</td>\n      <td>6.4</td>\n      <td>30.3</td>\n      <td>Inc Group 2</td>\n      <td>3.829485e+09</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>HH_60_75K</td>\n      <td>60000</td>\n      <td>74999.0</td>\n      <td>67500.0</td>\n      <td>104883</td>\n      <td>9.6</td>\n      <td>39.9</td>\n      <td>Inc Group 2</td>\n      <td>7.079602e+09</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>HH_75_100K</td>\n      <td>75000</td>\n      <td>99999.0</td>\n      <td>87500.0</td>\n      <td>159368</td>\n      <td>14.6</td>\n      <td>54.5</td>\n      <td>Inc Group 3</td>\n      <td>1.394470e+10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>HH_100_125K</td>\n      <td>100000</td>\n      <td>124999.0</td>\n      <td>112500.0</td>\n      <td>134089</td>\n      <td>12.2</td>\n      <td>66.7</td>\n      <td>Inc Group 3</td>\n      <td>1.508501e+10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>HH_125_150K</td>\n      <td>125000</td>\n      <td>149999.0</td>\n      <td>137500.0</td>\n      <td>102926</td>\n      <td>9.4</td>\n      <td>76.1</td>\n      <td>Inc Group 4</td>\n      <td>1.415232e+10</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>HH_150_200K</td>\n      <td>150000</td>\n      <td>199999.0</td>\n      <td>175000.0</td>\n      <td>124090</td>\n      <td>11.3</td>\n      <td>87.4</td>\n      <td>Inc Group 4</td>\n      <td>2.171575e+10</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>HH_GT_200K</td>\n      <td>200000</td>\n      <td>inf</td>\n      <td>300000.0</td>\n      <td>137560</td>\n      <td>12.6</td>\n      <td>100.0</td>\n      <td>Inc Group 4</td>\n      <td>4.126800e+10</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#297e0e1a .cell execution_count=10}\n``` {.python .cell-code}\n# Prepare data for seaborn\ndf_plot = df_inc_group.copy()\ndf_plot['Income Label'] = df_plot['Income Category'].str.replace('HH_', '').str.replace('_', ' - ')\ndf_plot['index'] = range(len(df_plot))\n\n# Define colors for each income group\npalette = {'Inc Group 1': '#3498db', 'Inc Group 2': '#2ecc71',\n           'Inc Group 3': '#f39c12', 'Inc Group 4': '#e74c3c'}\n\n# Set seaborn style and context\nsns.set_style(\"whitegrid\")\nsns.set_context(\"notebook\")\n\n# Create barplot using seaborn\n# plt.figure(figsize=(12, 6))\nsns.barplot(\n    data=df_plot,\n    x='index',\n    y='State HH',\n    hue='Inc Group',\n    palette=palette,\n    legend=True,\n    dodge=False\n)\n\n# Customize plot\nplt.xlabel('Income Category', fontsize=11, fontweight='bold')\nplt.ylabel('Number of Households', fontsize=11, fontweight='bold')\nplt.title('Utah Household Income Distribution by Quartile',\n          fontsize=13, fontweight='bold', pad=20)\n\n# Format y-axis with comma separator\nplt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, p: f'{x:,.0f}'))\n\n# Set x-axis labels\nplt.xticks(range(len(df_plot)), df_plot['Income Label'],\n           rotation=45, ha='right', fontsize=9)\n\n# Customize legend\nplt.legend(loc='upper left', frameon=True, fontsize=10, title='')\n\n# Grid styling\nplt.grid(axis='y', alpha=0.3, linestyle='--')\nplt.gca().set_axisbelow(True)\n\n# Remove top and right spines for cleaner look\nsns.despine()\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Household Income Distribution by Quartile](index_files/figure-html/cell-11-output-1.png){width=791 height=509}\n:::\n:::\n\n\n**What we find:** The visualization reveals Utah's income distribution shape. We see a concentration of households in middle-income brackets with smaller tails at the lower extreme. This indicates a relatively strong middle class. The quartile assignments allow us to create a simplified four-group segmentation suitable for model implementation while preserving the essential income-based variation in time values.\n\n### Median Income (in Model Base Year Dollars)\n\nTo calculate VOT, we need a single representative income value for each income segment. The median is preferable to the mean because it's less sensitive to extreme values and better represents the \"typical\" household in each group.\n\nWe calculate medians using two approaches:\n\n1. **Weighted average of bracket midpoints**: Using our lookup table midpoints and household counts\n2. **ACS-reported median**: The direct estimate from Table B19013\n\nThe weighted average approach typically produces a value slightly different from the ACS median due to our simplified midpoint assumptions. We calculate a correction factor to align our estimates with the official ACS median for the full population, then apply this same correction proportionally to the income group medians. This ensures internal consistency while respecting the authoritative ACS estimates.\n\n::: {#48112097 .cell execution_count=11}\n``` {.python .cell-code}\n# Define income categories\ncategories = {\n    'Average': df_inc_group,\n    'Low Inc': df_inc_group[df_inc_group['Inc Group'] == 'Inc Group 1'],\n    'High Inc': df_inc_group[df_inc_group['Inc Group'] != 'Inc Group 1']\n}\n\n# Calculate metrics for each category\nsummary_data = {}\nfor cat_name, cat_df in categories.items():\n    summary_data[cat_name] = {\n        'Sum HH': cat_df['State HH'].sum(),\n        'Sum HH * Inc': cat_df['HH_MedInc_Product'].sum(),\n    }\n    # Calculate unadjusted median income\n    summary_data[cat_name]['Unadj Med Inc'] = (\n        summary_data[cat_name]['Sum HH * Inc'] / summary_data[cat_name]['Sum HH']\n    )\n\n# Calculate correction factor from Average category\nactual_median_income = gdf_ut_income['HH_MED_INC'].iloc[0]\ncorrection_factor = actual_median_income / summary_data['Average']['Unadj Med Inc']\ninflation_factor = 1.0\n\n# Apply correction and inflation factors\nfor cat_name in summary_data:\n    summary_data[cat_name]['Correction Factor'] = correction_factor\n    summary_data[cat_name]['Adj Med Income'] = (\n        summary_data[cat_name]['Unadj Med Inc'] * correction_factor\n    )\n    summary_data[cat_name]['Inflation Adj Factor'] = inflation_factor\n    summary_data[cat_name]['Median Income'] = (\n        summary_data[cat_name]['Adj Med Income'] * inflation_factor\n    )\n\n# Convert to DataFrame\ndf_summary = pd.DataFrame(summary_data).T\n\n# Format for display\nformat_specs = {\n    'Sum HH': '{:,.0f}',\n    'Sum HH * Inc': '{:,.0f}',\n    'Unadj Med Inc': '${:,.0f}',\n    'Correction Factor': '{:.4f}',\n    'Adj Med Income': '${:,.0f}',\n    'Inflation Adj Factor': '{:.4f}',\n    'Median Income': '${:,.0f}'\n}\n\ndf_median_income = df_summary.copy()\nfor col, fmt in format_specs.items():\n    df_median_income[col] = df_summary[col].apply(lambda x: fmt.format(x))\n\ndf_median_income\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sum HH</th>\n      <th>Sum HH * Inc</th>\n      <th>Unadj Med Inc</th>\n      <th>Correction Factor</th>\n      <th>Adj Med Income</th>\n      <th>Inflation Adj Factor</th>\n      <th>Median Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Average</th>\n      <td>1,094,896</td>\n      <td>124,503,122,500</td>\n      <td>$113,712</td>\n      <td>0.8069</td>\n      <td>$91,750</td>\n      <td>1.0000</td>\n      <td>$91,750</td>\n    </tr>\n    <tr>\n      <th>Low Inc</th>\n      <td>262,353</td>\n      <td>7,428,247,500</td>\n      <td>$28,314</td>\n      <td>0.8069</td>\n      <td>$22,845</td>\n      <td>1.0000</td>\n      <td>$22,845</td>\n    </tr>\n    <tr>\n      <th>High Inc</th>\n      <td>832,543</td>\n      <td>117,074,875,000</td>\n      <td>$140,623</td>\n      <td>0.8069</td>\n      <td>$113,463</td>\n      <td>1.0000</td>\n      <td>$113,463</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**What we find:**\n\n- **Average Median Income**: The overall median for all Utah households, matching the ACS B19013 estimate\n- **Low Income Median**: The median for the bottom quartile, representing lower-wage workers, retirees on fixed incomes, and households with part-time employment\n- **High Income Median**: The median for the upper three quartiles combined, representing professional workers, dual-income households, and higher-wage earners\n\nThese three values form the foundation for calculating income-differentiated VOT parameters.\n\n### Value of Time (in Model Base Year Dollars)\n\nThe Value of Time converts annual income into an hourly rate, then applies purpose-specific multipliers to reflect how travelers trade off time and money for different trip types. The fundamental assumption is that VOT relates to income—higher earners value time more—but the relationship isn't one-to-one.\n\nResearch from revealed preference studies (toll usage patterns) and stated preference surveys consistently shows that:\n\n- People value work trip time at 35-50% of their wage rate (employers care about productivity, commuters care about stress and lost leisure)\n- People value personal trip time at 25-35% of their wage rate (pure leisure trade-off)\n- Commercial vehicles have higher VOT reflecting business operating costs beyond driver wages\n\nThe percentages we apply come from regional travel behavior studies, calibrated to match observed patterns in toll lane usage, route choice, and mode choice behavior.\n\n#### Calculate Hourly Income\n\nWe convert annual median income to an hourly rate by dividing by 2,080 hours (52 weeks × 40 hours/week). This assumes full-time, year-round employment, which is a standard convention in VOT estimation. While not every household member works full-time, this standardization allows consistent comparison across income groups and aligns with how wages are typically expressed.\n\n::: {#2f009370 .cell execution_count=12}\n``` {.python .cell-code}\n# Convert annual median income to hourly rate (assuming 2080 work hours/year)\ndf_hourly = pd.DataFrame({\n    'Median Income': df_summary['Median Income'],\n    'Hourly Rate': df_summary['Median Income'] / 2080\n}, index=['Average', 'Low Inc', 'High Inc'])\n\ndf_hourly.style.format({\n    'Median Income': '${:,.0f}',\n    'Hourly Rate': '${:.2f}'\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_741ed\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_741ed_level0_col0\" class=\"col_heading level0 col0\" >Median Income</th>\n      <th id=\"T_741ed_level0_col1\" class=\"col_heading level0 col1\" >Hourly Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_741ed_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n      <td id=\"T_741ed_row0_col0\" class=\"data row0 col0\" >$91,750</td>\n      <td id=\"T_741ed_row0_col1\" class=\"data row0 col1\" >$44.11</td>\n    </tr>\n    <tr>\n      <th id=\"T_741ed_level0_row1\" class=\"row_heading level0 row1\" >Low Inc</th>\n      <td id=\"T_741ed_row1_col0\" class=\"data row1 col0\" >$22,845</td>\n      <td id=\"T_741ed_row1_col1\" class=\"data row1 col1\" >$10.98</td>\n    </tr>\n    <tr>\n      <th id=\"T_741ed_level0_row2\" class=\"row_heading level0 row2\" >High Inc</th>\n      <td id=\"T_741ed_row2_col0\" class=\"data row2 col0\" >$113,463</td>\n      <td id=\"T_741ed_row2_col1\" class=\"data row2 col1\" >$54.55</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n**What we find:** The hourly rates provide an intuitive way to think about the opportunity cost of time. For example, if the average household has an hourly rate of \\$45, spending an hour in traffic has a notional cost of \\$45 in lost productive time or leisure.\n\n#### Calculate VOT in cents per mile\n\nThese hardcoded percentages represent the fraction of hourly wage that travelers implicitly value their travel time at, based on observed behavior in previous studies. The percentages differ by trip purpose because:\n\n**Work Trips (higher %)**: Include both the opportunity cost to the traveler AND the employer's interest in worker productivity. However, it's typically less than 100% of the wage because commute time is partially compensated through location choice (people choose home/work locations balancing commute time against housing costs and wages).\n\n**Personal Trips (lower %)**: Reflect pure leisure time trade-offs. People are willing to spend more time traveling when they have flexibility and the marginal utility of saved time is lower.\n\n**Income Effects**: Lower-income travelers often show higher VOT as a percentage of income for work trips (they can't afford to be late) but lower for personal trips (more time-flexible). Higher-income travelers show the opposite pattern.\n\n:::{.callout-important}\nThese percentages have been calibrated in previous model validation efforts to match observed behavior patterns in the region.\n:::\n\n::: {#9788f871 .cell execution_count=13}\n``` {.python .cell-code}\n# Define VOT as percentage of hourly income for each trip purpose and income group\n# Hardcoded VOT percentages from previous calculations\nvot_pct = pd.DataFrame({\n    'Work': [0.39, 0.62, 0.34],\n    'Personal': [0.30, 0.49, 0.27]\n}, index=['Average', 'Low Inc', 'High Inc'])\n```\n:::\n\n\n::: {#85e23f8d .cell execution_count=14}\n``` {.python .cell-code}\n# Calculate VOT in cents per minute (hourly rate * percentage * 100 / 60)\nvot_cents_min = ((df_hourly['Hourly Rate'].values[:, None] * vot_pct) * 100 / 60).round(0)\n\nvot_cents_min.style.format({\n    'Work': '${:.1f}',\n    'Personal': '${:.1f}'\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_368a1\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_368a1_level0_col0\" class=\"col_heading level0 col0\" >Work</th>\n      <th id=\"T_368a1_level0_col1\" class=\"col_heading level0 col1\" >Personal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_368a1_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n      <td id=\"T_368a1_row0_col0\" class=\"data row0 col0\" >$29.0</td>\n      <td id=\"T_368a1_row0_col1\" class=\"data row0 col1\" >$22.0</td>\n    </tr>\n    <tr>\n      <th id=\"T_368a1_level0_row1\" class=\"row_heading level0 row1\" >Low Inc</th>\n      <td id=\"T_368a1_row1_col0\" class=\"data row1 col0\" >$11.0</td>\n      <td id=\"T_368a1_row1_col1\" class=\"data row1 col1\" >$9.0</td>\n    </tr>\n    <tr>\n      <th id=\"T_368a1_level0_row2\" class=\"row_heading level0 row2\" >High Inc</th>\n      <td id=\"T_368a1_row2_col0\" class=\"data row2 col0\" >$31.0</td>\n      <td id=\"T_368a1_row2_col1\" class=\"data row2 col1\" >$25.0</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n#### Calculate and Display Work & Personal VOT\n\nWe now calculate the final VOT values in cents per minute, the standard unit for travel demand models. The conversion from dollars per hour to cents per minute (multiplying by 100, dividing by 60) makes the values easier to work with in network assignment algorithms where travel times are typically in minutes.\n\n**Work VOT Results:**\nThese values represent how much travelers implicitly pay (in toll charges, fuel costs, or inconvenience) to save one minute of travel time on work-related trips. Higher-income travelers have higher work VOT, reflecting both their higher opportunity cost and their greater ability to pay for time savings.\n\n::: {#3645aef8 .cell execution_count=15}\n``` {.python .cell-code}\n# Display Work VOT results\ndf_vot_work = pd.DataFrame({\n    '% of Income': vot_pct['Work'],\n    'Unrounded ($/hr)': df_hourly['Hourly Rate'] * vot_pct['Work'],\n    'VOT (¢/min)': vot_cents_min['Work'],\n    'Equivalent ($/hr)': vot_cents_min['Work'] * 60 / 100\n}, index=['Average', 'Low Inc', 'High Inc'])\n\ndf_vot_work.style.format({\n    '% of Income': '{:.0%}',\n    'Unrounded ($/hr)': '${:.2f}',\n    'VOT (¢/min)': '{:.0f}',\n    'Equivalent ($/hr)': '${:.2f}'\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_0d11f\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_0d11f_level0_col0\" class=\"col_heading level0 col0\" >% of Income</th>\n      <th id=\"T_0d11f_level0_col1\" class=\"col_heading level0 col1\" >Unrounded ($/hr)</th>\n      <th id=\"T_0d11f_level0_col2\" class=\"col_heading level0 col2\" >VOT (¢/min)</th>\n      <th id=\"T_0d11f_level0_col3\" class=\"col_heading level0 col3\" >Equivalent ($/hr)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_0d11f_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n      <td id=\"T_0d11f_row0_col0\" class=\"data row0 col0\" >39%</td>\n      <td id=\"T_0d11f_row0_col1\" class=\"data row0 col1\" >$17.20</td>\n      <td id=\"T_0d11f_row0_col2\" class=\"data row0 col2\" >29</td>\n      <td id=\"T_0d11f_row0_col3\" class=\"data row0 col3\" >$17.40</td>\n    </tr>\n    <tr>\n      <th id=\"T_0d11f_level0_row1\" class=\"row_heading level0 row1\" >Low Inc</th>\n      <td id=\"T_0d11f_row1_col0\" class=\"data row1 col0\" >62%</td>\n      <td id=\"T_0d11f_row1_col1\" class=\"data row1 col1\" >$6.81</td>\n      <td id=\"T_0d11f_row1_col2\" class=\"data row1 col2\" >11</td>\n      <td id=\"T_0d11f_row1_col3\" class=\"data row1 col3\" >$6.60</td>\n    </tr>\n    <tr>\n      <th id=\"T_0d11f_level0_row2\" class=\"row_heading level0 row2\" >High Inc</th>\n      <td id=\"T_0d11f_row2_col0\" class=\"data row2 col0\" >34%</td>\n      <td id=\"T_0d11f_row2_col1\" class=\"data row2 col1\" >$18.55</td>\n      <td id=\"T_0d11f_row2_col2\" class=\"data row2 col2\" >31</td>\n      <td id=\"T_0d11f_row2_col3\" class=\"data row2 col3\" >$18.60</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n**Personal VOT Results:**\nPersonal trip VOT is consistently lower than work VOT across all income groups. The relative difference between income groups is also more pronounced, as higher-income households have more discretionary income to trade for leisure time convenience.\n\n::: {#2e577fd6 .cell execution_count=16}\n``` {.python .cell-code}\n# Display Personal VOT results\ndf_vot_personal = pd.DataFrame({\n    '% of Income': vot_pct['Personal'],\n    'Unrounded ($/hr)': df_hourly['Hourly Rate'] * vot_pct['Personal'],\n    'VOT (¢/min)': vot_cents_min['Personal'],\n    'Equivalent ($/hr)': vot_cents_min['Personal'] * 60 / 100\n}, index=['Average', 'Low Inc', 'High Inc'])\n\ndf_vot_personal.style.format({\n    '% of Income': '{:.0%}',\n    'Unrounded ($/hr)': '${:.2f}',\n    'VOT (¢/min)': '{:.0f}',\n    'Equivalent ($/hr)': '${:.2f}'\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_d86fb\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_d86fb_level0_col0\" class=\"col_heading level0 col0\" >% of Income</th>\n      <th id=\"T_d86fb_level0_col1\" class=\"col_heading level0 col1\" >Unrounded ($/hr)</th>\n      <th id=\"T_d86fb_level0_col2\" class=\"col_heading level0 col2\" >VOT (¢/min)</th>\n      <th id=\"T_d86fb_level0_col3\" class=\"col_heading level0 col3\" >Equivalent ($/hr)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_d86fb_level0_row0\" class=\"row_heading level0 row0\" >Average</th>\n      <td id=\"T_d86fb_row0_col0\" class=\"data row0 col0\" >30%</td>\n      <td id=\"T_d86fb_row0_col1\" class=\"data row0 col1\" >$13.23</td>\n      <td id=\"T_d86fb_row0_col2\" class=\"data row0 col2\" >22</td>\n      <td id=\"T_d86fb_row0_col3\" class=\"data row0 col3\" >$13.20</td>\n    </tr>\n    <tr>\n      <th id=\"T_d86fb_level0_row1\" class=\"row_heading level0 row1\" >Low Inc</th>\n      <td id=\"T_d86fb_row1_col0\" class=\"data row1 col0\" >49%</td>\n      <td id=\"T_d86fb_row1_col1\" class=\"data row1 col1\" >$5.38</td>\n      <td id=\"T_d86fb_row1_col2\" class=\"data row1 col2\" >9</td>\n      <td id=\"T_d86fb_row1_col3\" class=\"data row1 col3\" >$5.40</td>\n    </tr>\n    <tr>\n      <th id=\"T_d86fb_level0_row2\" class=\"row_heading level0 row2\" >High Inc</th>\n      <td id=\"T_d86fb_row2_col0\" class=\"data row2 col0\" >27%</td>\n      <td id=\"T_d86fb_row2_col1\" class=\"data row2 col1\" >$14.73</td>\n      <td id=\"T_d86fb_row2_col2\" class=\"data row2 col2\" >25</td>\n      <td id=\"T_d86fb_row2_col3\" class=\"data row2 col3\" >$15.00</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n**Model Application:** These VOT values feed directly into the mode choice and route choice components of the travel demand model. For example, if a toll road saves 10 minutes compared to a free alternative, a traveler will choose the toll road if the toll cost is less than (10 minutes × VOT). The model predicts what fraction of travelers find the trade-off worthwhile based on their income segment and trip purpose distribution.\n\n#### Calculate and Display Truck VOT\n\nCommercial vehicle VOT requires a different framework than passenger vehicles because it reflects business operating costs rather than personal wage rates. Truck VOT includes:\n\n- Driver wages and benefits\n- Vehicle operating costs (fuel, maintenance, depreciation)\n- Cargo value and time-sensitivity\n- Business overhead and profit margins\n\nThe percentages (relative to average household income) are calibrated to match observed commercial vehicle behavior, particularly toll road usage patterns. Larger trucks have higher VOT because they carry more valuable cargo, have higher operating costs per hour, and typically serve time-sensitive delivery schedules.\n\n**Truck Categories:**\n\n- **Light Trucks**: Small commercial vehicles, delivery vans, service vehicles\n- **Medium Trucks**: Box trucks, small semi-trailers, regional delivery vehicles\n- **Heavy Trucks**: Large semi-trailers, long-haul freight, bulk cargo carriers\n\n:::{.callout-important}\nThese percentages have been calibrated in previous model validation efforts to match observed behavior patterns in the region.\n:::\n\n::: {#8a494757 .cell execution_count=17}\n``` {.python .cell-code}\n# Calculate Truck VOT (using Average income as base)\ntruck_pct = pd.Series([0.65, 0.87, 1.10], index=['Light', 'Medium', 'Heavy'])\n```\n:::\n\n\n::: {#4dbbd6b5 .cell execution_count=18}\n``` {.python .cell-code}\ndf_vot_trucks = pd.DataFrame({\n    '% of Income': truck_pct,\n    'Unrounded ($/hr)': df_hourly.loc['Average', 'Hourly Rate'] * truck_pct,\n    'VOT (¢/min)': ((df_hourly.loc['Average', 'Hourly Rate'] * truck_pct) * 100 / 60).round(0)\n})\n\ndf_vot_trucks['Equivalent ($/hr)'] = df_vot_trucks['VOT (¢/min)'] * 60 / 100\n\ndf_vot_trucks.style.format({\n    '% of Income': '{:.0%}',\n    'Unrounded ($/hr)': '${:.2f}',\n    'VOT (¢/min)': '{:.0f}',\n    'Equivalent ($/hr)': '${:.2f}'\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_100df\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_100df_level0_col0\" class=\"col_heading level0 col0\" >% of Income</th>\n      <th id=\"T_100df_level0_col1\" class=\"col_heading level0 col1\" >Unrounded ($/hr)</th>\n      <th id=\"T_100df_level0_col2\" class=\"col_heading level0 col2\" >VOT (¢/min)</th>\n      <th id=\"T_100df_level0_col3\" class=\"col_heading level0 col3\" >Equivalent ($/hr)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_100df_level0_row0\" class=\"row_heading level0 row0\" >Light</th>\n      <td id=\"T_100df_row0_col0\" class=\"data row0 col0\" >65%</td>\n      <td id=\"T_100df_row0_col1\" class=\"data row0 col1\" >$28.67</td>\n      <td id=\"T_100df_row0_col2\" class=\"data row0 col2\" >48</td>\n      <td id=\"T_100df_row0_col3\" class=\"data row0 col3\" >$28.80</td>\n    </tr>\n    <tr>\n      <th id=\"T_100df_level0_row1\" class=\"row_heading level0 row1\" >Medium</th>\n      <td id=\"T_100df_row1_col0\" class=\"data row1 col0\" >87%</td>\n      <td id=\"T_100df_row1_col1\" class=\"data row1 col1\" >$38.38</td>\n      <td id=\"T_100df_row1_col2\" class=\"data row1 col2\" >64</td>\n      <td id=\"T_100df_row1_col3\" class=\"data row1 col3\" >$38.40</td>\n    </tr>\n    <tr>\n      <th id=\"T_100df_level0_row2\" class=\"row_heading level0 row2\" >Heavy</th>\n      <td id=\"T_100df_row2_col0\" class=\"data row2 col0\" >110%</td>\n      <td id=\"T_100df_row2_col1\" class=\"data row2 col1\" >$48.52</td>\n      <td id=\"T_100df_row2_col2\" class=\"data row2 col2\" >81</td>\n      <td id=\"T_100df_row2_col3\" class=\"data row2 col3\" >$48.60</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n**What we find:** Heavy truck VOT can exceed $30/hour, reflecting the high cost of keeping valuable cargo and expensive equipment idle in traffic. This high VOT explains why commercial vehicles disproportionately use toll facilities and why freight routing is highly sensitive to congestion and travel time reliability.\n\n## Export Results\n\nThe final step packages our calculated VOT parameters in formats ready for model implementation and documentation.\n\n### Create Final VOT Table\n\nThis table assembles all VOT parameters into a single reference dataset matching the travel demand model's naming conventions. Each parameter corresponds to a specific traveler type and trip purpose combination:\n\n**Parameter Definitions:**\n\n- **VOT_Auto_Wrk**: Standard work trip VOT (average income)\n- **VOT_Auto_Per**: Standard personal trip VOT (average income)\n- **VOT_Auto_Ext**: External trips (average of work and personal, used for through-trips)\n- **VOT_LT, VOT_MD, VOT_HV**: Light, medium, and heavy truck VOT\n- **VOT_Auto_Wrk_Lo, VOT_Auto_Per_Lo**: Low-income work and personal trip VOT\n- **VOT_Auto_Wrk_Hi, VOT_Auto_Per_Hi**: High-income work and personal trip VOT\n\nThe table displays values in both cents per minute (for model input) and dollars per hour (for intuitive interpretation).\n\n::: {#7f008691 .cell execution_count=19}\n``` {.python .cell-code}\n# Build the final VOT parameters table\ndf_vot_params = pd.DataFrame({\n    'Parameter': [\n        'VOT_Auto_Wrk', 'VOT_Auto_Per', 'VOT_Auto_Ext',\n        'VOT_LT', 'VOT_MD', 'VOT_HV',\n        'VOT_Auto_Wrk_Lo', 'VOT_Auto_Per_Lo',\n        'VOT_Auto_Wrk_Hi', 'VOT_Auto_Per_Hi'\n    ],\n    'VOT (cent/min)': [\n        vot_cents_min.loc['Average', 'Work'],\n        vot_cents_min.loc['Average', 'Personal'],\n        (vot_cents_min.loc['Average', 'Work'] + vot_cents_min.loc['Average', 'Personal']) / 2,\n        df_vot_trucks.loc['Light', 'VOT (¢/min)'],\n        df_vot_trucks.loc['Medium', 'VOT (¢/min)'],\n        df_vot_trucks.loc['Heavy', 'VOT (¢/min)'],\n        vot_cents_min.loc['Low Inc', 'Work'],\n        vot_cents_min.loc['Low Inc', 'Personal'],\n        vot_cents_min.loc['High Inc', 'Work'],\n        vot_cents_min.loc['High Inc', 'Personal']\n    ]\n})\n\ndf_vot_params['VOT ($/hr)'] = df_vot_params['VOT (cent/min)'] * 60 / 100\n\ndf_vot_params.style.format({\n    'VOT (cent/min)': '{:.0f}¢',\n    'VOT ($/hr)': '${:.1f}'\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<style type=\"text/css\">\n</style>\n<table id=\"T_97ee7\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_97ee7_level0_col0\" class=\"col_heading level0 col0\" >Parameter</th>\n      <th id=\"T_97ee7_level0_col1\" class=\"col_heading level0 col1\" >VOT (cent/min)</th>\n      <th id=\"T_97ee7_level0_col2\" class=\"col_heading level0 col2\" >VOT ($/hr)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_97ee7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n      <td id=\"T_97ee7_row0_col0\" class=\"data row0 col0\" >VOT_Auto_Wrk</td>\n      <td id=\"T_97ee7_row0_col1\" class=\"data row0 col1\" >29¢</td>\n      <td id=\"T_97ee7_row0_col2\" class=\"data row0 col2\" >$17.4</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n      <td id=\"T_97ee7_row1_col0\" class=\"data row1 col0\" >VOT_Auto_Per</td>\n      <td id=\"T_97ee7_row1_col1\" class=\"data row1 col1\" >22¢</td>\n      <td id=\"T_97ee7_row1_col2\" class=\"data row1 col2\" >$13.2</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n      <td id=\"T_97ee7_row2_col0\" class=\"data row2 col0\" >VOT_Auto_Ext</td>\n      <td id=\"T_97ee7_row2_col1\" class=\"data row2 col1\" >26¢</td>\n      <td id=\"T_97ee7_row2_col2\" class=\"data row2 col2\" >$15.3</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n      <td id=\"T_97ee7_row3_col0\" class=\"data row3 col0\" >VOT_LT</td>\n      <td id=\"T_97ee7_row3_col1\" class=\"data row3 col1\" >48¢</td>\n      <td id=\"T_97ee7_row3_col2\" class=\"data row3 col2\" >$28.8</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n      <td id=\"T_97ee7_row4_col0\" class=\"data row4 col0\" >VOT_MD</td>\n      <td id=\"T_97ee7_row4_col1\" class=\"data row4 col1\" >64¢</td>\n      <td id=\"T_97ee7_row4_col2\" class=\"data row4 col2\" >$38.4</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n      <td id=\"T_97ee7_row5_col0\" class=\"data row5 col0\" >VOT_HV</td>\n      <td id=\"T_97ee7_row5_col1\" class=\"data row5 col1\" >81¢</td>\n      <td id=\"T_97ee7_row5_col2\" class=\"data row5 col2\" >$48.6</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n      <td id=\"T_97ee7_row6_col0\" class=\"data row6 col0\" >VOT_Auto_Wrk_Lo</td>\n      <td id=\"T_97ee7_row6_col1\" class=\"data row6 col1\" >11¢</td>\n      <td id=\"T_97ee7_row6_col2\" class=\"data row6 col2\" >$6.6</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n      <td id=\"T_97ee7_row7_col0\" class=\"data row7 col0\" >VOT_Auto_Per_Lo</td>\n      <td id=\"T_97ee7_row7_col1\" class=\"data row7 col1\" >9¢</td>\n      <td id=\"T_97ee7_row7_col2\" class=\"data row7 col2\" >$5.4</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n      <td id=\"T_97ee7_row8_col0\" class=\"data row8 col0\" >VOT_Auto_Wrk_Hi</td>\n      <td id=\"T_97ee7_row8_col1\" class=\"data row8 col1\" >31¢</td>\n      <td id=\"T_97ee7_row8_col2\" class=\"data row8 col2\" >$18.6</td>\n    </tr>\n    <tr>\n      <th id=\"T_97ee7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n      <td id=\"T_97ee7_row9_col0\" class=\"data row9 col0\" >VOT_Auto_Per_Hi</td>\n      <td id=\"T_97ee7_row9_col1\" class=\"data row9 col1\" >25¢</td>\n      <td id=\"T_97ee7_row9_col2\" class=\"data row9 col2\" >$15.0</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n### Export to CSV\n\nWe export the final VOT parameters to a CSV file for easy integration into the travel demand model configuration. This file becomes the authoritative source for VOT parameters, documenting the values used in model runs and providing traceability back to the source data and methodology.\n\n::: {#0c321ac4 .cell execution_count=20}\n``` {.python .cell-code}\n# Create output directory if it doesn't exist\noutput_dir = Path(\"_output\")\noutput_dir.mkdir(parents=True, exist_ok=True)\n\n# Export to CSV\ndf_vot_params.to_csv(\n    output_dir / \"value_of_time.csv\",\n    index=False\n)\n```\n:::\n\n\nThe exported file can be version-controlled alongside the model, ensuring that any changes to VOT assumptions are tracked and documented. When updating the model to new base years or recalibrating with new income data, this notebook can be re-run to generate updated VOT parameters consistently.\n\n::: {.callout-tip title=\"Download the output files:\"}\n[value_of_time.csv](./_output/value_of_time.csv)\n:::\n\n",
    "supporting": [
      "index_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js\" integrity=\"sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js\" integrity=\"sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}